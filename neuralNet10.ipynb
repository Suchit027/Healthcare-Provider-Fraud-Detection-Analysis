{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, p1, p2, p3):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Linear(31, 70, bias= True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(70, 70, bias= True),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(70),\n",
    "            nn.Dropout(p = p1),\n",
    "            nn.Linear(70, 65, bias = True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(65, 60, bias= True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 60, bias= True),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(60),\n",
    "            nn.Dropout(p= p2),\n",
    "            nn.Linear(60, 55, bias= True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(55, 50, bias= True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 45, bias= True),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(45),\n",
    "            nn.Dropout(p= p3),\n",
    "            nn.Linear(45, 40, bias= True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 35, bias = True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(35, 25, bias = True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(25, 20, bias = True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 15, bias = True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(15, 10, bias = True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 5, bias = True)\n",
    "        )\n",
    "        self.classify = nn.Sequential(\n",
    "            nn.Linear(5, 1, bias= True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.classify(self.features(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__()\n",
    "        self.x = torch.tensor(x.values, dtype= torch.float32)\n",
    "        self.y = torch.tensor(y.values, dtype= torch.float32)\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.x[index], self.y[index]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, ytrain, xtest, ytest = pd.read_csv('./X_train.csv', header= None, index_col = None), pd.read_csv('./y_train.csv', header = None, index_col = None), pd.read_csv('./X_test.csv', header = None, index_col = None), pd.read_csv('./y_test.csv', header = None, index_col = None)\n",
    "train_data = Data(x= xtrain, y= ytrain)\n",
    "test_data = Data(x= xtest, y= ytest)\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle= True)\n",
    "test_loader = DataLoader(test_data, batch_size= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (features): Sequential(\n",
       "    (0): Linear(in_features=31, out_features=70, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=70, out_features=70, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): BatchNorm1d(70, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): Dropout(p=0.3, inplace=False)\n",
       "    (6): Linear(in_features=70, out_features=65, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=65, out_features=60, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): Linear(in_features=60, out_features=60, bias=True)\n",
       "    (11): ReLU()\n",
       "    (12): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): Dropout(p=0.4, inplace=False)\n",
       "    (14): Linear(in_features=60, out_features=55, bias=True)\n",
       "    (15): ReLU()\n",
       "    (16): Linear(in_features=55, out_features=50, bias=True)\n",
       "    (17): ReLU()\n",
       "    (18): Linear(in_features=50, out_features=45, bias=True)\n",
       "    (19): ReLU()\n",
       "    (20): BatchNorm1d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (21): Dropout(p=0.5, inplace=False)\n",
       "    (22): Linear(in_features=45, out_features=40, bias=True)\n",
       "    (23): ReLU()\n",
       "    (24): Linear(in_features=40, out_features=35, bias=True)\n",
       "    (25): ReLU()\n",
       "    (26): Linear(in_features=35, out_features=25, bias=True)\n",
       "    (27): ReLU()\n",
       "    (28): Linear(in_features=25, out_features=20, bias=True)\n",
       "    (29): ReLU()\n",
       "    (30): Linear(in_features=20, out_features=15, bias=True)\n",
       "    (31): ReLU()\n",
       "    (32): Linear(in_features=15, out_features=10, bias=True)\n",
       "    (33): ReLU()\n",
       "    (34): Linear(in_features=10, out_features=5, bias=True)\n",
       "  )\n",
       "  (classify): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=1, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network(0.3, 0.4, 0.5)\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001, weight_decay= 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss - 3354.4005964398384\n",
      "loss - 3312.427163004875\n",
      "loss - 3309.135870575905\n",
      "loss - 3304.976012289524\n",
      "loss - 3302.1072465777397\n",
      "loss - 3300.681672334671\n",
      "loss - 3300.098206460476\n",
      "loss - 3297.8582020401955\n",
      "loss - 3296.639211654663\n",
      "loss - 3294.0527215600014\n",
      "loss - 3291.0620310902596\n",
      "loss - 3286.3524579405785\n",
      "loss - 3283.7237365841866\n",
      "loss - 3281.5054998397827\n",
      "loss - 3278.0625408887863\n",
      "loss - 3275.3903953433037\n",
      "loss - 3273.4190098047256\n",
      "loss - 3271.7306696772575\n",
      "loss - 3269.89005279541\n",
      "loss - 3267.6477927565575\n",
      "loss - 3266.172672212124\n",
      "loss - 3263.2795248031616\n",
      "loss - 3262.482297837734\n",
      "loss - 3260.7339245676994\n",
      "loss - 3259.112396776676\n",
      "loss - 3257.55293571949\n",
      "loss - 3256.171060502529\n",
      "loss - 3254.837429225445\n",
      "loss - 3251.877080142498\n",
      "loss - 3250.7915112376213\n",
      "loss - 3250.5899205207825\n",
      "loss - 3249.324480652809\n",
      "loss - 3247.7417810559273\n",
      "loss - 3246.1314554214478\n",
      "loss - 3244.9616725444794\n",
      "loss - 3244.6356514692307\n",
      "loss - 3241.300848186016\n",
      "loss - 3241.926243185997\n",
      "loss - 3239.9771254062653\n",
      "loss - 3239.7374120354652\n",
      "loss - 3239.83051776886\n",
      "loss - 3238.7306964993477\n",
      "loss - 3237.45324832201\n",
      "loss - 3236.626429617405\n",
      "loss - 3234.130814254284\n",
      "loss - 3233.2350754141808\n",
      "loss - 3233.3006298542023\n",
      "loss - 3231.811455786228\n",
      "loss - 3230.57568359375\n",
      "loss - 3229.0102105736732\n",
      "loss - 3228.750751912594\n",
      "loss - 3227.4457871317863\n",
      "loss - 3226.5464492440224\n",
      "loss - 3226.0569749474525\n",
      "loss - 3224.903466761112\n",
      "loss - 3223.050424218178\n",
      "loss - 3223.545600116253\n",
      "loss - 3222.7848358750343\n",
      "loss - 3221.0059233903885\n",
      "loss - 3219.5624754428864\n",
      "loss - 3219.1972438693047\n",
      "loss - 3218.060694694519\n",
      "loss - 3216.5972297787666\n",
      "loss - 3217.4717876315117\n",
      "loss - 3215.8316974043846\n",
      "loss - 3214.891748189926\n",
      "loss - 3213.384600818157\n",
      "loss - 3211.7517364025116\n",
      "loss - 3211.1796181201935\n",
      "loss - 3210.4300059080124\n",
      "loss - 3207.439992725849\n",
      "loss - 3206.7626370191574\n",
      "loss - 3208.6662971377373\n",
      "loss - 3206.3417597413063\n",
      "loss - 3204.6278685331345\n",
      "loss - 3204.7610768079758\n",
      "loss - 3202.918932020664\n",
      "loss - 3202.8515279889107\n",
      "loss - 3203.342417359352\n",
      "loss - 3201.4171494841576\n",
      "loss - 3200.4219802618027\n",
      "loss - 3197.991906583309\n",
      "loss - 3197.7400873303413\n",
      "loss - 3199.0105439424515\n",
      "loss - 3198.3289397358894\n",
      "loss - 3194.8462806344032\n",
      "loss - 3194.5472566485405\n",
      "loss - 3194.3926842808723\n",
      "loss - 3193.8156774044037\n",
      "loss - 3194.778296172619\n",
      "loss - 3191.290892779827\n",
      "loss - 3191.7154846787453\n",
      "loss - 3191.9252659082413\n",
      "loss - 3191.5049533247948\n",
      "loss - 3188.8496538996696\n",
      "loss - 3189.8098152279854\n",
      "loss - 3189.038896203041\n",
      "loss - 3186.8126069903374\n",
      "loss - 3186.39335334301\n",
      "loss - 3185.2841202020645\n",
      "loss - 3185.3524649739265\n",
      "loss - 3184.1330196857452\n",
      "loss - 3183.4690323472023\n",
      "loss - 3184.3869044184685\n",
      "loss - 3182.9607706665993\n",
      "loss - 3182.5718368291855\n",
      "loss - 3180.5375170707703\n",
      "loss - 3180.32045006752\n",
      "loss - 3178.3532789945602\n",
      "loss - 3178.823554992676\n",
      "loss - 3177.5218492150307\n",
      "loss - 3179.0565861463547\n",
      "loss - 3176.438236296177\n",
      "loss - 3176.688435256481\n",
      "loss - 3174.356059372425\n",
      "loss - 3173.947292983532\n",
      "loss - 3174.5899932980537\n",
      "loss - 3173.4181331396103\n",
      "loss - 3173.483154475689\n",
      "loss - 3171.289026260376\n",
      "loss - 3172.248306930065\n",
      "loss - 3170.145913183689\n",
      "loss - 3168.5975779294968\n",
      "loss - 3168.9497901797295\n",
      "loss - 3168.89692312479\n",
      "loss - 3167.128242790699\n",
      "loss - 3168.1600638628006\n",
      "loss - 3166.3412155508995\n",
      "loss - 3166.7905145287514\n",
      "loss - 3165.491053700447\n",
      "loss - 3165.7756364941597\n",
      "loss - 3163.066492676735\n",
      "loss - 3163.285949230194\n",
      "loss - 3163.7556459903717\n",
      "loss - 3161.2387905716896\n",
      "loss - 3162.2636026144028\n",
      "loss - 3161.318535089493\n",
      "loss - 3160.3118552565575\n",
      "loss - 3160.613623738289\n",
      "loss - 3159.952976703644\n",
      "loss - 3159.968404829502\n",
      "loss - 3158.3661165237427\n",
      "loss - 3157.214748620987\n",
      "loss - 3156.62370377779\n",
      "loss - 3154.649091154337\n",
      "loss - 3155.1831127405167\n",
      "loss - 3154.785987317562\n",
      "loss - 3153.5303468704224\n",
      "loss - 3154.8728110194206\n",
      "loss - 3151.8676761984825\n",
      "loss - 3151.60386377573\n",
      "loss - 3150.8019468784332\n",
      "loss - 3151.90193015337\n",
      "loss - 3149.776819884777\n",
      "loss - 3148.6054114103317\n",
      "loss - 3148.542619049549\n",
      "loss - 3147.9487615823746\n",
      "loss - 3146.65600335598\n",
      "loss - 3146.8766226768494\n",
      "loss - 3144.7056462168694\n",
      "loss - 3145.2150359749794\n",
      "loss - 3143.552321732044\n",
      "loss - 3143.537273287773\n",
      "loss - 3144.389502644539\n",
      "loss - 3142.1964027881622\n",
      "loss - 3142.205282866955\n",
      "loss - 3142.641696125269\n",
      "loss - 3141.061977624893\n",
      "loss - 3139.6101882457733\n",
      "loss - 3140.4576566815376\n",
      "loss - 3138.7655212283134\n",
      "loss - 3138.7147251963615\n",
      "loss - 3139.2595109939575\n",
      "loss - 3137.0466818213463\n",
      "loss - 3137.7252440452576\n",
      "loss - 3137.0457777380943\n",
      "loss - 3135.892054259777\n",
      "loss - 3136.9613477885723\n",
      "loss - 3135.101046651602\n",
      "loss - 3135.834035694599\n",
      "loss - 3134.7137801647186\n",
      "loss - 3133.9603953957558\n",
      "loss - 3134.36925137043\n",
      "loss - 3133.0619500279427\n",
      "loss - 3134.3974296450615\n",
      "loss - 3133.805485725403\n",
      "loss - 3130.8140029907227\n",
      "loss - 3131.6838992238045\n",
      "loss - 3131.7687934935093\n",
      "loss - 3130.469451546669\n",
      "loss - 3129.816881477833\n",
      "loss - 3128.0610025525093\n",
      "loss - 3128.2534298300743\n",
      "loss - 3127.8208762407303\n",
      "loss - 3129.4150210618973\n",
      "loss - 3125.394564449787\n",
      "loss - 3126.50244602561\n",
      "loss - 3125.7191480994225\n",
      "loss - 3125.8800778388977\n",
      "loss - 3126.9831821918488\n",
      "loss - 3125.442391693592\n",
      "loss - 3123.61080878973\n",
      "loss - 3125.081998705864\n",
      "loss - 3124.7735255360603\n",
      "loss - 3122.935875892639\n",
      "loss - 3122.5409007668495\n",
      "loss - 3123.446775853634\n",
      "loss - 3123.779749453068\n",
      "loss - 3122.8173322081566\n",
      "loss - 3120.5791098475456\n",
      "loss - 3120.081859856844\n",
      "loss - 3119.989438056946\n",
      "loss - 3120.7519000172615\n",
      "loss - 3119.969982624054\n",
      "loss - 3117.9080889821053\n",
      "loss - 3117.586240172386\n",
      "loss - 3117.5453788638115\n",
      "loss - 3117.99754434824\n",
      "loss - 3114.6640983223915\n",
      "loss - 3115.8340950012207\n",
      "loss - 3115.1246173381805\n",
      "loss - 3114.8611370921135\n",
      "loss - 3114.5197332799435\n",
      "loss - 3114.2851198613644\n",
      "loss - 3113.4322938024998\n",
      "loss - 3114.0204550027847\n",
      "loss - 3113.8149487376213\n",
      "loss - 3111.1984094381332\n",
      "loss - 3113.5590037107468\n",
      "loss - 3113.612228035927\n",
      "loss - 3111.8739970326424\n",
      "loss - 3109.397224485874\n",
      "loss - 3107.088610827923\n",
      "loss - 3109.9636939466\n",
      "loss - 3109.3622846603394\n",
      "loss - 3108.434671521187\n",
      "loss - 3110.169376075268\n",
      "loss - 3108.1218489706516\n",
      "loss - 3108.7755072414875\n",
      "loss - 3107.916281402111\n",
      "loss - 3106.8556337058544\n",
      "loss - 3106.6671541035175\n",
      "loss - 3106.866490036249\n",
      "loss - 3106.2042831480503\n",
      "loss - 3106.5169618725777\n",
      "loss - 3102.6079216599464\n",
      "loss - 3104.895494878292\n",
      "loss - 3105.046756565571\n",
      "loss - 3105.3008719682693\n",
      "loss - 3106.7577404379845\n",
      "loss - 3103.596840262413\n",
      "loss - 3103.065095305443\n",
      "loss - 3100.020229101181\n",
      "loss - 3102.396390557289\n",
      "loss - 3103.803889811039\n",
      "loss - 3103.2554965019226\n",
      "loss - 3101.9255534112453\n",
      "loss - 3101.217565178871\n",
      "loss - 3101.923913538456\n",
      "loss - 3099.6752590835094\n",
      "loss - 3099.700224339962\n",
      "loss - 3099.582946151495\n",
      "loss - 3097.9854440391064\n",
      "loss - 3097.8000511825085\n",
      "loss - 3097.0853991508484\n",
      "loss - 3098.3718597590923\n",
      "loss - 3097.8015588521957\n",
      "loss - 3097.180513203144\n",
      "loss - 3095.4367364645004\n",
      "loss - 3094.461210846901\n",
      "loss - 3095.6464601159096\n",
      "loss - 3095.994508177042\n",
      "loss - 3096.076338171959\n",
      "loss - 3095.45127671957\n",
      "loss - 3094.5083956718445\n",
      "loss - 3094.7148836553097\n",
      "loss - 3092.6183460354805\n",
      "loss - 3093.4510201215744\n",
      "loss - 3092.141248613596\n",
      "loss - 3093.237266689539\n",
      "loss - 3091.8800014853477\n",
      "loss - 3091.3033379018307\n",
      "loss - 3090.0851038992405\n",
      "loss - 3092.0886795520782\n",
      "loss - 3090.2546775341034\n",
      "loss - 3091.6161292791367\n",
      "loss - 3092.3352330327034\n",
      "loss - 3090.567731231451\n",
      "loss - 3090.4623951613903\n",
      "loss - 3089.3817095458508\n",
      "loss - 3089.925583690405\n",
      "loss - 3088.813517987728\n",
      "loss - 3086.1752565801144\n",
      "loss - 3086.577897876501\n",
      "loss - 3088.595735192299\n",
      "loss - 3086.09004932642\n",
      "loss - 3087.5074901282787\n",
      "loss - 3087.4192884266376\n",
      "loss - 3088.5091921687126\n",
      "loss - 3085.601203531027\n",
      "loss - 3085.5037786364555\n",
      "loss - 3086.2413586974144\n",
      "loss - 3083.0611206293106\n",
      "loss - 3084.2571517527103\n",
      "loss - 3081.86424857378\n",
      "loss - 3084.5191107988358\n",
      "loss - 3083.342100650072\n",
      "loss - 3081.933070152998\n",
      "loss - 3080.629106670618\n",
      "loss - 3081.8379634320736\n",
      "loss - 3081.4818709790707\n",
      "loss - 3079.1917307674885\n",
      "loss - 3078.3724079430103\n",
      "loss - 3079.8927126526833\n",
      "loss - 3079.530896216631\n",
      "loss - 3079.522033959627\n",
      "loss - 3081.513784199953\n",
      "loss - 3080.0515207350254\n",
      "loss - 3079.7750129401684\n",
      "loss - 3078.9459168314934\n",
      "loss - 3077.482567846775\n",
      "loss - 3078.369590431452\n",
      "loss - 3077.639032870531\n",
      "loss - 3077.934696227312\n",
      "loss - 3075.3851078748703\n",
      "loss - 3075.8323993086815\n",
      "loss - 3075.4915368258953\n",
      "loss - 3075.8562130331993\n",
      "loss - 3075.153235256672\n",
      "loss - 3076.8259584903717\n",
      "loss - 3075.276677906513\n",
      "loss - 3075.3216396570206\n",
      "loss - 3073.979172408581\n",
      "loss - 3073.9017069637775\n",
      "loss - 3074.4201405346394\n",
      "loss - 3074.428643077612\n",
      "loss - 3073.280141800642\n",
      "loss - 3074.0182423591614\n",
      "loss - 3071.0988080501556\n",
      "loss - 3072.6008594036102\n",
      "loss - 3070.146417796612\n",
      "loss - 3071.2905575335026\n",
      "loss - 3070.0020604133606\n",
      "loss - 3071.61271828413\n",
      "loss - 3070.710544884205\n",
      "loss - 3068.99147939682\n",
      "loss - 3070.439795434475\n",
      "loss - 3068.083502948284\n",
      "loss - 3068.976305991411\n",
      "loss - 3069.7065427303314\n",
      "loss - 3067.81018987298\n",
      "loss - 3069.77143779397\n",
      "loss - 3068.824592202902\n",
      "loss - 3067.660035789013\n",
      "loss - 3067.751926034689\n",
      "loss - 3066.5654674470425\n",
      "loss - 3068.3142262995243\n",
      "loss - 3065.9584657251835\n",
      "loss - 3066.9343470335007\n",
      "loss - 3063.4039770662785\n",
      "loss - 3066.4254353642464\n",
      "loss - 3064.689040929079\n",
      "loss - 3065.3909460902214\n",
      "loss - 3062.109691530466\n",
      "loss - 3065.6254203617573\n",
      "loss - 3064.950194954872\n",
      "loss - 3066.8234972655773\n",
      "loss - 3065.1448499262333\n",
      "loss - 3064.28965690732\n",
      "loss - 3061.3816879689693\n",
      "loss - 3063.515221774578\n",
      "loss - 3062.2269340753555\n",
      "loss - 3062.500557422638\n",
      "loss - 3061.4384612441063\n",
      "loss - 3064.7400533258915\n",
      "loss - 3063.0977848768234\n",
      "loss - 3061.1934750676155\n",
      "loss - 3059.866804122925\n",
      "loss - 3062.3536903858185\n",
      "loss - 3057.248474061489\n",
      "loss - 3061.7515794038773\n",
      "loss - 3059.202980309725\n",
      "loss - 3060.2821816802025\n",
      "loss - 3058.4524824619293\n",
      "loss - 3059.726665198803\n",
      "loss - 3058.351000994444\n",
      "loss - 3059.1031496822834\n",
      "loss - 3057.9297097325325\n",
      "loss - 3056.7636824846268\n",
      "loss - 3057.4003695845604\n",
      "loss - 3058.2866839766502\n",
      "loss - 3056.090320646763\n",
      "loss - 3059.613250911236\n",
      "loss - 3053.734949618578\n",
      "loss - 3058.645448565483\n",
      "loss - 3056.941759735346\n",
      "loss - 3055.160117983818\n",
      "loss - 3056.4429070949554\n",
      "loss - 3055.8614534437656\n",
      "loss - 3053.8923290371895\n",
      "loss - 3055.5826281011105\n",
      "loss - 3054.128273308277\n",
      "loss - 3051.6766835451126\n",
      "loss - 3052.6733082830906\n",
      "loss - 3053.1605754196644\n",
      "loss - 3053.2527384459972\n",
      "loss - 3051.217451184988\n",
      "loss - 3054.1560340821743\n",
      "loss - 3051.176157206297\n",
      "loss - 3051.582229524851\n",
      "loss - 3050.9215215444565\n",
      "loss - 3050.017422646284\n",
      "loss - 3050.6626565158367\n",
      "loss - 3050.9201313257217\n",
      "loss - 3050.8447108864784\n",
      "loss - 3048.3197640776634\n",
      "loss - 3051.784707069397\n",
      "loss - 3050.9184531867504\n",
      "loss - 3052.914831072092\n",
      "loss - 3045.835767477751\n",
      "loss - 3051.783075481653\n",
      "loss - 3051.7498168349266\n",
      "loss - 3049.057449042797\n",
      "loss - 3046.5186487436295\n",
      "loss - 3049.488144427538\n",
      "loss - 3047.8792639672756\n",
      "loss - 3048.1971104443073\n",
      "loss - 3051.2943398058414\n",
      "loss - 3046.675195336342\n",
      "loss - 3048.92414945364\n",
      "loss - 3046.7461158931255\n",
      "loss - 3045.7711955606937\n",
      "loss - 3047.6374266445637\n",
      "loss - 3045.220910489559\n",
      "loss - 3045.482377886772\n",
      "loss - 3045.8985194265842\n",
      "loss - 3045.796416193247\n",
      "loss - 3047.301297158003\n",
      "loss - 3047.0294550955296\n",
      "loss - 3046.286475419998\n",
      "loss - 3043.66493588686\n",
      "loss - 3046.2124777436256\n",
      "loss - 3042.43969848752\n",
      "loss - 3046.1082694530487\n",
      "loss - 3044.694774210453\n",
      "loss - 3043.7864747047424\n",
      "loss - 3043.981425702572\n",
      "loss - 3039.792329341173\n",
      "loss - 3046.388522863388\n",
      "loss - 3041.398288220167\n",
      "loss - 3041.5250321924686\n",
      "loss - 3044.0939458310604\n",
      "loss - 3039.6699027121067\n",
      "loss - 3042.3002677559853\n",
      "loss - 3041.1637157797813\n",
      "loss - 3042.513839483261\n",
      "loss - 3040.8007083833218\n",
      "loss - 3040.3026116490364\n",
      "loss - 3039.8206109702587\n",
      "loss - 3040.262330621481\n",
      "loss - 3040.9522329568863\n",
      "loss - 3037.5648173093796\n",
      "loss - 3038.5518771111965\n",
      "loss - 3040.204986900091\n",
      "loss - 3041.5633081793785\n",
      "loss - 3038.9601832926273\n",
      "loss - 3039.7535539269447\n",
      "loss - 3036.7256706655025\n",
      "loss - 3039.312742561102\n",
      "loss - 3036.7598471939564\n",
      "loss - 3039.80205065012\n",
      "loss - 3041.100370436907\n",
      "loss - 3039.8123658299446\n",
      "loss - 3037.943031400442\n",
      "loss - 3034.7252728939056\n",
      "loss - 3035.580055773258\n",
      "loss - 3036.3388023376465\n",
      "loss - 3037.657690793276\n",
      "loss - 3035.67667478323\n",
      "loss - 3034.621024608612\n",
      "loss - 3036.6574669778347\n",
      "loss - 3035.759293317795\n",
      "loss - 3036.3274185955524\n",
      "loss - 3035.3958810269833\n",
      "loss - 3034.1686975955963\n",
      "loss - 3034.2378569841385\n",
      "loss - 3035.6321111619473\n",
      "loss - 3034.8025192320347\n",
      "loss - 3036.1424202620983\n",
      "loss - 3033.7065514326096\n",
      "loss - 3031.459200948477\n",
      "loss - 3030.812165170908\n",
      "loss - 3034.5143561661243\n",
      "loss - 3033.3999675512314\n",
      "loss - 3032.732354849577\n",
      "loss - 3033.3495219945908\n",
      "loss - 3033.31891182065\n",
      "loss - 3032.27651360631\n",
      "loss - 3031.0625470876694\n",
      "loss - 3033.4633304178715\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(500):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for input, target in train_loader:\n",
    "        input, target = input.to('cuda'), target.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'loss - {running_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6437246963562753\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for input, target in test_loader:\n",
    "        input, target = input.to('cuda'), target.to('cuda')\n",
    "        output = torch.round(model(input))\n",
    "        all_preds.extend(output.to('cpu'))\n",
    "        all_labels.extend(target.to('cpu'))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(all_preds, all_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45851589447189334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "print(precision_score(all_preds, all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4972953844598352\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(all_preds, all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5432405566600398\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "print(recall_score(all_preds, all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
