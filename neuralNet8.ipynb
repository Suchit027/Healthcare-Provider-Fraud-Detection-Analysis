{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, p1, p2):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Linear(31, 60, bias= True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 60, bias= True),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p= p1),\n",
    "            nn.Linear(60, 55, bias = True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(55, 50, bias= True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 50, bias= True),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p= p2),\n",
    "            nn.Linear(50, 45, bias= True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(45, 40, bias= True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 35, bias= True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(35, 30, bias= True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30, 25, bias = True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(25, 20, bias = True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 15, bias = True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(15, 10, bias = True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 5, bias = True)\n",
    "        )\n",
    "        self.classify = nn.Sequential(\n",
    "            nn.Linear(5, 1, bias= True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.classify(self.features(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__()\n",
    "        self.x = torch.tensor(x.values, dtype= torch.float32)\n",
    "        self.y = torch.tensor(y.values, dtype= torch.float32)\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.x[index], self.y[index]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, ytrain, xtest, ytest = pd.read_csv('./X_train.csv', header= None, index_col = None), pd.read_csv('./y_train.csv', header = None, index_col = None), pd.read_csv('./X_test.csv', header = None, index_col = None), pd.read_csv('./y_test.csv', header = None, index_col = None)\n",
    "train_data = Data(x= xtrain, y= ytrain)\n",
    "test_data = Data(x= xtest, y= ytest)\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle= True)\n",
    "test_loader = DataLoader(test_data, batch_size= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (features): Sequential(\n",
       "    (0): Linear(in_features=31, out_features=60, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=60, out_features=60, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Dropout(p=0.3, inplace=False)\n",
       "    (5): Linear(in_features=60, out_features=55, bias=True)\n",
       "    (6): ReLU()\n",
       "    (7): Linear(in_features=55, out_features=50, bias=True)\n",
       "    (8): ReLU()\n",
       "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout(p=0.6, inplace=False)\n",
       "    (12): Linear(in_features=50, out_features=45, bias=True)\n",
       "    (13): ReLU()\n",
       "    (14): Linear(in_features=45, out_features=40, bias=True)\n",
       "    (15): ReLU()\n",
       "    (16): Linear(in_features=40, out_features=35, bias=True)\n",
       "    (17): ReLU()\n",
       "    (18): Linear(in_features=35, out_features=30, bias=True)\n",
       "    (19): ReLU()\n",
       "    (20): Linear(in_features=30, out_features=25, bias=True)\n",
       "    (21): ReLU()\n",
       "    (22): Linear(in_features=25, out_features=20, bias=True)\n",
       "    (23): ReLU()\n",
       "    (24): Linear(in_features=20, out_features=15, bias=True)\n",
       "    (25): ReLU()\n",
       "    (26): Linear(in_features=15, out_features=10, bias=True)\n",
       "    (27): ReLU()\n",
       "    (28): Linear(in_features=10, out_features=5, bias=True)\n",
       "  )\n",
       "  (classify): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=1, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network(0.3, 0.6)\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001, weight_decay= 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss - 3321.24760222435\n",
      "loss - 3311.4658472537994\n",
      "loss - 3308.8696380853653\n",
      "loss - 3308.0276544094086\n",
      "loss - 3307.732715547085\n",
      "loss - 3307.6249402165413\n",
      "loss - 3307.601688683033\n",
      "loss - 3307.486014008522\n",
      "loss - 3307.554578900337\n",
      "loss - 3305.4195892214775\n",
      "loss - 3300.088252067566\n",
      "loss - 3296.2837846279144\n",
      "loss - 3293.774529516697\n",
      "loss - 3293.0360924601555\n",
      "loss - 3291.3375826478004\n",
      "loss - 3290.2111157774925\n",
      "loss - 3289.625064074993\n",
      "loss - 3289.033482849598\n",
      "loss - 3288.1224403977394\n",
      "loss - 3286.4788682460785\n",
      "loss - 3286.2285990715027\n",
      "loss - 3285.6048377752304\n",
      "loss - 3284.830412507057\n",
      "loss - 3284.0441341400146\n",
      "loss - 3284.1068559885025\n",
      "loss - 3283.1753460764885\n",
      "loss - 3282.3257467746735\n",
      "loss - 3282.3370019197464\n",
      "loss - 3282.4154876470566\n",
      "loss - 3281.1546808481216\n",
      "loss - 3280.977334201336\n",
      "loss - 3279.7261368632317\n",
      "loss - 3280.2690665125847\n",
      "loss - 3278.797425210476\n",
      "loss - 3278.675228834152\n",
      "loss - 3278.0596626400948\n",
      "loss - 3277.483148932457\n",
      "loss - 3277.0376688838005\n",
      "loss - 3276.555063188076\n",
      "loss - 3276.0243052840233\n",
      "loss - 3275.8907232880592\n",
      "loss - 3275.871441602707\n",
      "loss - 3274.934128642082\n",
      "loss - 3274.2029218673706\n",
      "loss - 3274.008113384247\n",
      "loss - 3274.004384636879\n",
      "loss - 3274.334020256996\n",
      "loss - 3272.4433759450912\n",
      "loss - 3272.321593105793\n",
      "loss - 3272.1709198355675\n",
      "loss - 3271.4317024350166\n",
      "loss - 3270.4252548217773\n",
      "loss - 3269.647211790085\n",
      "loss - 3269.359689950943\n",
      "loss - 3269.1071751713753\n",
      "loss - 3269.294769525528\n",
      "loss - 3267.9647153019905\n",
      "loss - 3268.5041414499283\n",
      "loss - 3267.701464354992\n",
      "loss - 3267.009738624096\n",
      "loss - 3266.6079320311546\n",
      "loss - 3265.87034368515\n",
      "loss - 3264.997848510742\n",
      "loss - 3265.0186027884483\n",
      "loss - 3264.0377348065376\n",
      "loss - 3263.8595616817474\n",
      "loss - 3263.6441323161125\n",
      "loss - 3262.4358664155006\n",
      "loss - 3261.9459646344185\n",
      "loss - 3262.0784965753555\n",
      "loss - 3261.2402383089066\n",
      "loss - 3260.044899702072\n",
      "loss - 3260.386894226074\n",
      "loss - 3259.2841351628304\n",
      "loss - 3258.2265560626984\n",
      "loss - 3257.2023959755898\n",
      "loss - 3255.6159259676933\n",
      "loss - 3254.959071934223\n",
      "loss - 3252.522403717041\n",
      "loss - 3251.551316320896\n",
      "loss - 3250.8740995526314\n",
      "loss - 3249.7254306077957\n",
      "loss - 3248.6962735056877\n",
      "loss - 3248.165419459343\n",
      "loss - 3247.2015550732613\n",
      "loss - 3246.196046292782\n",
      "loss - 3246.030047118664\n",
      "loss - 3244.718435585499\n",
      "loss - 3245.5806351304054\n",
      "loss - 3244.0842522978783\n",
      "loss - 3243.164873421192\n",
      "loss - 3242.103887617588\n",
      "loss - 3241.4055453538895\n",
      "loss - 3240.6124373078346\n",
      "loss - 3240.3201972842216\n",
      "loss - 3237.9337800741196\n",
      "loss - 3236.9771461486816\n",
      "loss - 3235.690403521061\n",
      "loss - 3235.167502760887\n",
      "loss - 3235.1965895295143\n",
      "loss - 3232.3890545368195\n",
      "loss - 3232.126284480095\n",
      "loss - 3230.159829378128\n",
      "loss - 3229.626465022564\n",
      "loss - 3227.4973818063736\n",
      "loss - 3228.242013633251\n",
      "loss - 3226.5961668491364\n",
      "loss - 3226.086104094982\n",
      "loss - 3225.4996904730797\n",
      "loss - 3224.4881443977356\n",
      "loss - 3224.802000582218\n",
      "loss - 3222.6779586672783\n",
      "loss - 3224.274244070053\n",
      "loss - 3223.362595975399\n",
      "loss - 3222.4498113393784\n",
      "loss - 3219.014864563942\n",
      "loss - 3219.281283199787\n",
      "loss - 3220.407487154007\n",
      "loss - 3219.855203270912\n",
      "loss - 3219.2344693541527\n",
      "loss - 3218.697895526886\n",
      "loss - 3217.567309319973\n",
      "loss - 3219.0838901400566\n",
      "loss - 3216.3578363656998\n",
      "loss - 3215.1598286628723\n",
      "loss - 3216.407938539982\n",
      "loss - 3214.6887575984\n",
      "loss - 3213.54021692276\n",
      "loss - 3214.3723145127296\n",
      "loss - 3211.8509857058525\n",
      "loss - 3210.6649829149246\n",
      "loss - 3214.430277824402\n",
      "loss - 3220.1460154652596\n",
      "loss - 3219.834954559803\n",
      "loss - 3217.657582104206\n",
      "loss - 3218.2358614206314\n",
      "loss - 3217.0214025974274\n",
      "loss - 3214.9022356271744\n",
      "loss - 3212.7971484661102\n",
      "loss - 3214.2817826867104\n",
      "loss - 3211.625847876072\n",
      "loss - 3209.823846042156\n",
      "loss - 3209.239686012268\n",
      "loss - 3208.745451271534\n",
      "loss - 3209.70764875412\n",
      "loss - 3207.6557710766792\n",
      "loss - 3205.2248755693436\n",
      "loss - 3205.5691561698914\n",
      "loss - 3205.919908821583\n",
      "loss - 3201.732655465603\n",
      "loss - 3202.3148669600487\n",
      "loss - 3202.9446867108345\n",
      "loss - 3199.4536324739456\n",
      "loss - 3200.751361012459\n",
      "loss - 3202.881364583969\n",
      "loss - 3199.4414219260216\n",
      "loss - 3195.9518586993217\n",
      "loss - 3196.3729974627495\n",
      "loss - 3196.8595913648605\n",
      "loss - 3197.718501150608\n",
      "loss - 3195.940937280655\n",
      "loss - 3194.3358092308044\n",
      "loss - 3194.5060938596725\n",
      "loss - 3194.2977448403835\n",
      "loss - 3193.510518312454\n",
      "loss - 3192.782797932625\n",
      "loss - 3195.028170824051\n",
      "loss - 3197.09676194191\n",
      "loss - 3212.364733994007\n",
      "loss - 3221.175111949444\n",
      "loss - 3206.368822991848\n",
      "loss - 3207.6437653303146\n",
      "loss - 3203.63389647007\n",
      "loss - 3193.7351348996162\n",
      "loss - 3216.7529103159904\n",
      "loss - 3214.759169757366\n",
      "loss - 3210.4933418035507\n",
      "loss - 3207.8976746201515\n",
      "loss - 3207.364577591419\n",
      "loss - 3202.3224228024483\n",
      "loss - 3203.7144514918327\n",
      "loss - 3203.690116107464\n",
      "loss - 3204.7002767920494\n",
      "loss - 3200.3955730199814\n",
      "loss - 3202.384337604046\n",
      "loss - 3207.2117159366608\n",
      "loss - 3206.3919119238853\n",
      "loss - 3200.8579924702644\n",
      "loss - 3198.0702596902847\n",
      "loss - 3196.6397111415863\n",
      "loss - 3194.8028564453125\n",
      "loss - 3195.5756219029427\n",
      "loss - 3194.6543830037117\n",
      "loss - 3191.027237534523\n",
      "loss - 3192.665891587734\n",
      "loss - 3187.257938325405\n",
      "loss - 3187.6430995464325\n",
      "loss - 3187.5419017076492\n",
      "loss - 3198.3153702020645\n",
      "loss - 3195.4552236795425\n",
      "loss - 3193.821209490299\n",
      "loss - 3192.370565533638\n",
      "loss - 3193.3838579654694\n",
      "loss - 3186.5473644137383\n",
      "loss - 3186.4347049593925\n",
      "loss - 3185.4782180190086\n",
      "loss - 3184.0031361579895\n",
      "loss - 3182.81240439415\n",
      "loss - 3183.7039751410484\n",
      "loss - 3184.347929060459\n",
      "loss - 3183.074508011341\n",
      "loss - 3184.3981397151947\n",
      "loss - 3182.351197898388\n",
      "loss - 3179.8811658620834\n",
      "loss - 3181.6280752420425\n",
      "loss - 3183.5771332383156\n",
      "loss - 3178.87108117342\n",
      "loss - 3175.6800079345703\n",
      "loss - 3176.8245401382446\n",
      "loss - 3176.0754271149635\n",
      "loss - 3188.060220360756\n",
      "loss - 3186.856082737446\n",
      "loss - 3180.8384270966053\n",
      "loss - 3183.4140417575836\n",
      "loss - 3178.3915585279465\n",
      "loss - 3176.5174768567085\n",
      "loss - 3174.689774632454\n",
      "loss - 3171.3619161248207\n",
      "loss - 3170.235740184784\n",
      "loss - 3170.13341742754\n",
      "loss - 3171.900239467621\n",
      "loss - 3173.2756509184837\n",
      "loss - 3174.7195749282837\n",
      "loss - 3168.652711391449\n",
      "loss - 3181.5386070609093\n",
      "loss - 3178.3263877630234\n",
      "loss - 3177.1526255607605\n",
      "loss - 3172.594471514225\n",
      "loss - 3170.442321538925\n",
      "loss - 3173.3346633911133\n",
      "loss - 3171.422918498516\n",
      "loss - 3170.101249575615\n",
      "loss - 3171.122146844864\n",
      "loss - 3171.3488001823425\n",
      "loss - 3165.1686832010746\n",
      "loss - 3168.275859296322\n",
      "loss - 3173.5558621287346\n",
      "loss - 3172.5217097997665\n",
      "loss - 3169.1940590143204\n",
      "loss - 3171.3018662929535\n",
      "loss - 3169.499032318592\n",
      "loss - 3167.831607401371\n",
      "loss - 3165.917128741741\n",
      "loss - 3163.505068063736\n",
      "loss - 3167.6358944773674\n",
      "loss - 3164.3122757077217\n",
      "loss - 3161.519814014435\n",
      "loss - 3166.9003804326057\n",
      "loss - 3161.920930147171\n",
      "loss - 3159.782316327095\n",
      "loss - 3159.84959256649\n",
      "loss - 3161.480896294117\n",
      "loss - 3165.6491055488586\n",
      "loss - 3162.90927195549\n",
      "loss - 3159.242365717888\n",
      "loss - 3162.167944550514\n",
      "loss - 3154.252923309803\n",
      "loss - 3158.146851837635\n",
      "loss - 3156.5432375073433\n",
      "loss - 3156.8435755372047\n",
      "loss - 3159.483873128891\n",
      "loss - 3156.1078159213066\n",
      "loss - 3154.6545082330704\n",
      "loss - 3160.0387033820152\n",
      "loss - 3160.924253463745\n",
      "loss - 3154.588913023472\n",
      "loss - 3155.1169769763947\n",
      "loss - 3152.1674144268036\n",
      "loss - 3147.381046742201\n",
      "loss - 3154.021702647209\n",
      "loss - 3151.273459613323\n",
      "loss - 3153.9816222190857\n",
      "loss - 3154.518648147583\n",
      "loss - 3152.0370237231255\n",
      "loss - 3149.3676402568817\n",
      "loss - 3151.9237176179886\n",
      "loss - 3153.1342841386795\n",
      "loss - 3143.942384034395\n",
      "loss - 3148.700892865658\n",
      "loss - 3149.513920009136\n",
      "loss - 3148.433320403099\n",
      "loss - 3146.9709790349007\n",
      "loss - 3150.6657720804214\n",
      "loss - 3153.565790593624\n",
      "loss - 3152.098999083042\n",
      "loss - 3157.230769097805\n",
      "loss - 3154.832397043705\n",
      "loss - 3145.401991903782\n",
      "loss - 3145.4337220191956\n",
      "loss - 3148.539547920227\n",
      "loss - 3151.66131991148\n",
      "loss - 3145.40085542202\n",
      "loss - 3145.8837409615517\n",
      "loss - 3147.044803738594\n",
      "loss - 3146.5201255083084\n",
      "loss - 3142.880751043558\n",
      "loss - 3142.127474665642\n",
      "loss - 3139.820889353752\n",
      "loss - 3145.723076045513\n",
      "loss - 3151.1744551062584\n",
      "loss - 3148.3367832899094\n",
      "loss - 3145.2314261198044\n",
      "loss - 3151.718418419361\n",
      "loss - 3147.2813598513603\n",
      "loss - 3141.085393190384\n",
      "loss - 3143.9733712673187\n",
      "loss - 3140.5491783618927\n",
      "loss - 3138.722294449806\n",
      "loss - 3141.617977678776\n",
      "loss - 3144.4785680174828\n",
      "loss - 3142.184412419796\n",
      "loss - 3136.7868414521217\n",
      "loss - 3139.2117542028427\n",
      "loss - 3136.074177801609\n",
      "loss - 3139.7770343124866\n",
      "loss - 3133.9945207238197\n",
      "loss - 3135.903324365616\n",
      "loss - 3137.8142718672752\n",
      "loss - 3136.117720246315\n",
      "loss - 3149.493170827627\n",
      "loss - 3150.9281622469425\n",
      "loss - 3145.407346189022\n",
      "loss - 3159.6567846536636\n",
      "loss - 3154.904283106327\n",
      "loss - 3147.0416374206543\n",
      "loss - 3161.2026282846928\n",
      "loss - 3149.4931393265724\n",
      "loss - 3143.6591970920563\n",
      "loss - 3139.292198777199\n",
      "loss - 3140.9199408888817\n",
      "loss - 3137.6710676550865\n",
      "loss - 3142.450105011463\n",
      "loss - 3136.976371407509\n",
      "loss - 3137.092786371708\n",
      "loss - 3135.365530848503\n",
      "loss - 3139.9411966204643\n",
      "loss - 3133.9944997131824\n",
      "loss - 3133.966160058975\n",
      "loss - 3134.183115005493\n",
      "loss - 3137.3061776161194\n",
      "loss - 3131.355780273676\n",
      "loss - 3133.9531193971634\n",
      "loss - 3133.714274227619\n",
      "loss - 3129.172964811325\n",
      "loss - 3130.8417271971703\n",
      "loss - 3129.0644015073776\n",
      "loss - 3129.57340580225\n",
      "loss - 3131.204979658127\n",
      "loss - 3142.303704023361\n",
      "loss - 3139.08251285553\n",
      "loss - 3149.1998787522316\n",
      "loss - 3130.9568226337433\n",
      "loss - 3128.497294187546\n",
      "loss - 3143.59588727355\n",
      "loss - 3127.8906555771828\n",
      "loss - 3131.839410305023\n",
      "loss - 3141.9134971499443\n",
      "loss - 3139.0585909187794\n",
      "loss - 3138.6770153045654\n",
      "loss - 3129.47980093956\n",
      "loss - 3128.0669156312943\n",
      "loss - 3129.402316570282\n",
      "loss - 3126.5966054797173\n",
      "loss - 3131.0776111483574\n",
      "loss - 3127.549588173628\n",
      "loss - 3128.6028516590595\n",
      "loss - 3123.1772142350674\n",
      "loss - 3128.783091723919\n",
      "loss - 3128.291064620018\n",
      "loss - 3133.952528119087\n",
      "loss - 3133.432846426964\n",
      "loss - 3126.7901272773743\n",
      "loss - 3124.319490045309\n",
      "loss - 3123.014456510544\n",
      "loss - 3126.1680220663548\n",
      "loss - 3122.894067466259\n",
      "loss - 3120.471319079399\n",
      "loss - 3127.213941037655\n",
      "loss - 3133.3676855266094\n",
      "loss - 3125.0822476148605\n",
      "loss - 3120.9364939928055\n",
      "loss - 3123.91511747241\n",
      "loss - 3124.4534873366356\n",
      "loss - 3134.2345317602158\n",
      "loss - 3123.087775528431\n",
      "loss - 3121.9290341436863\n",
      "loss - 3126.0429813563824\n",
      "loss - 3125.4671546816826\n",
      "loss - 3125.06323748827\n",
      "loss - 3126.3853414058685\n",
      "loss - 3121.163232624531\n",
      "loss - 3134.7821277976036\n",
      "loss - 3128.933546125889\n",
      "loss - 3121.670161128044\n",
      "loss - 3117.8711547255516\n",
      "loss - 3132.0587294101715\n",
      "loss - 3123.535280048847\n",
      "loss - 3147.518418908119\n",
      "loss - 3121.7895030379295\n",
      "loss - 3121.2206429839134\n",
      "loss - 3120.1019825935364\n",
      "loss - 3119.919704735279\n",
      "loss - 3123.3170664310455\n",
      "loss - 3127.246124088764\n",
      "loss - 3120.4606007933617\n",
      "loss - 3123.417405575514\n",
      "loss - 3127.3687129616737\n",
      "loss - 3125.0878344774246\n",
      "loss - 3125.308445394039\n",
      "loss - 3129.9232902526855\n",
      "loss - 3113.8210791647434\n",
      "loss - 3116.946580886841\n",
      "loss - 3120.582811653614\n",
      "loss - 3118.4509449005127\n",
      "loss - 3115.759464800358\n",
      "loss - 3128.612397402525\n",
      "loss - 3120.9341101646423\n",
      "loss - 3117.466426193714\n",
      "loss - 3119.644495487213\n",
      "loss - 3119.173293054104\n",
      "loss - 3115.3646565675735\n",
      "loss - 3123.8783314824104\n",
      "loss - 3117.183796674013\n",
      "loss - 3115.2558747529984\n",
      "loss - 3116.3062059283257\n",
      "loss - 3112.7995971143246\n",
      "loss - 3112.0573782622814\n",
      "loss - 3121.8714476823807\n",
      "loss - 3122.1501186192036\n",
      "loss - 3111.581258893013\n",
      "loss - 3115.191173315048\n",
      "loss - 3110.552848368883\n",
      "loss - 3113.549624413252\n",
      "loss - 3111.683033287525\n",
      "loss - 3116.9507236480713\n",
      "loss - 3120.7979333996773\n",
      "loss - 3118.474664181471\n",
      "loss - 3114.2273730039597\n",
      "loss - 3109.68878826499\n",
      "loss - 3118.884292602539\n",
      "loss - 3109.3826690912247\n",
      "loss - 3113.511065274477\n",
      "loss - 3123.376536011696\n",
      "loss - 3117.423919439316\n",
      "loss - 3115.1186792850494\n",
      "loss - 3112.6560566425323\n",
      "loss - 3111.7619940936565\n",
      "loss - 3124.083781391382\n",
      "loss - 3122.0603461265564\n",
      "loss - 3116.4570834338665\n",
      "loss - 3115.2125243246555\n",
      "loss - 3117.8538602292538\n",
      "loss - 3121.3307752013206\n",
      "loss - 3115.598355293274\n",
      "loss - 3122.692046523094\n",
      "loss - 3109.23086643219\n",
      "loss - 3113.7521689236164\n",
      "loss - 3108.325493901968\n",
      "loss - 3109.841822743416\n",
      "loss - 3120.3810682296753\n",
      "loss - 3113.6566603779793\n",
      "loss - 3108.897339642048\n",
      "loss - 3128.157713621855\n",
      "loss - 3118.0602075457573\n",
      "loss - 3120.831975400448\n",
      "loss - 3123.575744062662\n",
      "loss - 3114.2417534589767\n",
      "loss - 3110.0049044191837\n",
      "loss - 3115.0987772345543\n",
      "loss - 3111.9393756985664\n",
      "loss - 3117.437348663807\n",
      "loss - 3125.683084011078\n",
      "loss - 3113.9539830088615\n",
      "loss - 3119.3910331726074\n",
      "loss - 3109.8378671109676\n",
      "loss - 3111.161517471075\n",
      "loss - 3110.9231892228127\n",
      "loss - 3112.203280597925\n",
      "loss - 3114.698999196291\n",
      "loss - 3109.9612429142\n",
      "loss - 3110.2797013521194\n",
      "loss - 3107.02312707901\n",
      "loss - 3111.6006724238396\n",
      "loss - 3110.845721721649\n",
      "loss - 3114.755127221346\n",
      "loss - 3113.026724100113\n",
      "loss - 3109.1503343582153\n",
      "loss - 3109.527834802866\n",
      "loss - 3108.8936811983585\n",
      "loss - 3144.422843694687\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(500):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for input, target in train_loader:\n",
    "        input, target = input.to('cuda'), target.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'loss - {running_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.599297767905127\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for input, target in test_loader:\n",
    "        input, target = input.to('cuda'), target.to('cuda')\n",
    "        output = torch.round(model(input))\n",
    "        all_preds.extend(output.to('cpu'))\n",
    "        all_labels.extend(target.to('cpu'))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(all_preds, all_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
