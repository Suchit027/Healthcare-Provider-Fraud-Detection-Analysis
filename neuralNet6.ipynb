{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, p1, p2):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Linear(31, 50, bias= True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 50, bias= True),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p= p1),\n",
    "            nn.Linear(50, 45, bias = True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(45, 40, bias= True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 40, bias= True),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p= p2),\n",
    "            nn.Linear(40, 30, bias= True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30, 25, bias= True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(25, 20, bias= True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 15, bias= True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(15, 10, bias = True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 5, bias = True),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.classify = nn.Sequential(\n",
    "            nn.Linear(5, 1, bias= True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.classify(self.features(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__()\n",
    "        self.x = torch.tensor(x.values, dtype= torch.float32)\n",
    "        self.y = torch.tensor(y.values, dtype= torch.float32)\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.x[index], self.y[index]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, ytrain, xtest, ytest = pd.read_csv('./X_train.csv', header= None, index_col = None), pd.read_csv('./y_train.csv', header = None, index_col = None), pd.read_csv('./X_test.csv', header = None, index_col = None), pd.read_csv('./y_test.csv', header = None, index_col = None)\n",
    "train_data = Data(x= xtrain, y= ytrain)\n",
    "test_data = Data(x= xtest, y= ytest)\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle= True)\n",
    "test_loader = DataLoader(test_data, batch_size= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (features): Sequential(\n",
       "    (0): Linear(in_features=31, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Dropout(p=0.3, inplace=False)\n",
       "    (5): Linear(in_features=50, out_features=45, bias=True)\n",
       "    (6): ReLU()\n",
       "    (7): Linear(in_features=45, out_features=40, bias=True)\n",
       "    (8): ReLU()\n",
       "    (9): Linear(in_features=40, out_features=40, bias=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout(p=0.6, inplace=False)\n",
       "    (12): Linear(in_features=40, out_features=30, bias=True)\n",
       "    (13): ReLU()\n",
       "    (14): Linear(in_features=30, out_features=25, bias=True)\n",
       "    (15): ReLU()\n",
       "    (16): Linear(in_features=25, out_features=20, bias=True)\n",
       "    (17): ReLU()\n",
       "    (18): Linear(in_features=20, out_features=15, bias=True)\n",
       "    (19): ReLU()\n",
       "    (20): Linear(in_features=15, out_features=10, bias=True)\n",
       "    (21): ReLU()\n",
       "    (22): Linear(in_features=10, out_features=5, bias=True)\n",
       "    (23): ReLU()\n",
       "  )\n",
       "  (classify): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=1, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network(0.3, 0.6)\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001, weight_decay= 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss - 3327.011797785759\n",
      "loss - 3315.528683960438\n",
      "loss - 3313.1963059306145\n",
      "loss - 3309.9206636548042\n",
      "loss - 3305.7126828432083\n",
      "loss - 3300.873572945595\n",
      "loss - 3298.735218465328\n",
      "loss - 3297.0859273076057\n",
      "loss - 3295.5609126091003\n",
      "loss - 3294.936773478985\n",
      "loss - 3294.1416498422623\n",
      "loss - 3292.83951741457\n",
      "loss - 3291.76499325037\n",
      "loss - 3290.712089717388\n",
      "loss - 3289.3188887238503\n",
      "loss - 3288.6895500421524\n",
      "loss - 3286.4146760702133\n",
      "loss - 3286.4320939183235\n",
      "loss - 3283.735194683075\n",
      "loss - 3281.6708720326424\n",
      "loss - 3278.817104458809\n",
      "loss - 3276.030276298523\n",
      "loss - 3272.5797830224037\n",
      "loss - 3270.8911404013634\n",
      "loss - 3269.3712481856346\n",
      "loss - 3269.5003615021706\n",
      "loss - 3266.8577151298523\n",
      "loss - 3266.9860305786133\n",
      "loss - 3265.5582768917084\n",
      "loss - 3264.7908462285995\n",
      "loss - 3263.9965721964836\n",
      "loss - 3262.673334658146\n",
      "loss - 3261.7048082351685\n",
      "loss - 3260.6684809327126\n",
      "loss - 3259.6910140514374\n",
      "loss - 3258.5579754710197\n",
      "loss - 3257.740830242634\n",
      "loss - 3256.8678206801414\n",
      "loss - 3254.4135489463806\n",
      "loss - 3253.537524998188\n",
      "loss - 3252.3079226613045\n",
      "loss - 3250.3193133473396\n",
      "loss - 3248.7667959332466\n",
      "loss - 3247.2520141601562\n",
      "loss - 3244.7826750278473\n",
      "loss - 3244.358689904213\n",
      "loss - 3243.223660826683\n",
      "loss - 3239.970123589039\n",
      "loss - 3239.7864153385162\n",
      "loss - 3238.9802329540253\n",
      "loss - 3238.4204534888268\n",
      "loss - 3236.837606191635\n",
      "loss - 3236.7644199728966\n",
      "loss - 3235.0317935943604\n",
      "loss - 3234.5352013111115\n",
      "loss - 3233.6230956315994\n",
      "loss - 3233.9392374157906\n",
      "loss - 3232.8133417367935\n",
      "loss - 3230.9941903352737\n",
      "loss - 3231.0782347917557\n",
      "loss - 3230.4808046221733\n",
      "loss - 3228.4284643530846\n",
      "loss - 3226.87598913908\n",
      "loss - 3226.5860531926155\n",
      "loss - 3226.772044301033\n",
      "loss - 3225.582493841648\n",
      "loss - 3225.019162297249\n",
      "loss - 3224.1247024536133\n",
      "loss - 3223.604728937149\n",
      "loss - 3223.777382194996\n",
      "loss - 3221.7313829660416\n",
      "loss - 3220.416004896164\n",
      "loss - 3220.000907123089\n",
      "loss - 3220.5437626242638\n",
      "loss - 3219.953263938427\n",
      "loss - 3218.3822758197784\n",
      "loss - 3218.9222551584244\n",
      "loss - 3218.6948699355125\n",
      "loss - 3216.6048607230186\n",
      "loss - 3218.70537173748\n",
      "loss - 3216.5947428941727\n",
      "loss - 3213.799898326397\n",
      "loss - 3212.853091478348\n",
      "loss - 3213.6343918442726\n",
      "loss - 3212.430887699127\n",
      "loss - 3211.954356133938\n",
      "loss - 3210.709616422653\n",
      "loss - 3210.3323385715485\n",
      "loss - 3208.2126303315163\n",
      "loss - 3209.589255928993\n",
      "loss - 3208.8824706077576\n",
      "loss - 3207.43396037817\n",
      "loss - 3207.937709093094\n",
      "loss - 3206.3695674538612\n",
      "loss - 3205.4369062781334\n",
      "loss - 3205.277591764927\n",
      "loss - 3206.486120223999\n",
      "loss - 3204.7989735007286\n",
      "loss - 3203.118131697178\n",
      "loss - 3203.262532889843\n",
      "loss - 3202.176150202751\n",
      "loss - 3202.591312587261\n",
      "loss - 3201.3369538784027\n",
      "loss - 3201.326907813549\n",
      "loss - 3199.221886396408\n",
      "loss - 3197.249280154705\n",
      "loss - 3197.5594276189804\n",
      "loss - 3196.9399396181107\n",
      "loss - 3198.8157653212547\n",
      "loss - 3198.184684187174\n",
      "loss - 3196.91778331995\n",
      "loss - 3195.826335310936\n",
      "loss - 3197.4790697693825\n",
      "loss - 3196.223454296589\n",
      "loss - 3193.5648562312126\n",
      "loss - 3193.4776740074158\n",
      "loss - 3193.032540023327\n",
      "loss - 3193.4200808405876\n",
      "loss - 3194.2780475616455\n",
      "loss - 3193.7291237711906\n",
      "loss - 3193.133963763714\n",
      "loss - 3193.7265890836716\n",
      "loss - 3193.0634076595306\n",
      "loss - 3190.60359531641\n",
      "loss - 3192.749509334564\n",
      "loss - 3189.1022222042084\n",
      "loss - 3190.087462902069\n",
      "loss - 3188.533687710762\n",
      "loss - 3189.3747284412384\n",
      "loss - 3189.3730943202972\n",
      "loss - 3188.7582554221153\n",
      "loss - 3188.260466337204\n",
      "loss - 3187.7074758410454\n",
      "loss - 3188.44188195467\n",
      "loss - 3185.2062464356422\n",
      "loss - 3187.3242993354797\n",
      "loss - 3190.5093287825584\n",
      "loss - 3187.4306708574295\n",
      "loss - 3185.043313384056\n",
      "loss - 3184.4920558333397\n",
      "loss - 3183.652002930641\n",
      "loss - 3186.0348908901215\n",
      "loss - 3181.671748459339\n",
      "loss - 3183.2355858683586\n",
      "loss - 3182.976370215416\n",
      "loss - 3184.1863099336624\n",
      "loss - 3182.5304550528526\n",
      "loss - 3181.4649416804314\n",
      "loss - 3182.8467675447464\n",
      "loss - 3181.1112542152405\n",
      "loss - 3179.9606935977936\n",
      "loss - 3180.385614693165\n",
      "loss - 3179.866927921772\n",
      "loss - 3181.6572444438934\n",
      "loss - 3179.2500188052654\n",
      "loss - 3177.8453856110573\n",
      "loss - 3177.7226245999336\n",
      "loss - 3178.924311220646\n",
      "loss - 3178.7954243421555\n",
      "loss - 3178.096187055111\n",
      "loss - 3177.959225177765\n",
      "loss - 3178.7931235432625\n",
      "loss - 3176.885223567486\n",
      "loss - 3175.2127898335457\n",
      "loss - 3175.050271332264\n",
      "loss - 3174.0917021632195\n",
      "loss - 3176.8667330145836\n",
      "loss - 3175.435892164707\n",
      "loss - 3175.568421661854\n",
      "loss - 3174.5830305218697\n",
      "loss - 3172.70675355196\n",
      "loss - 3172.8570259213448\n",
      "loss - 3171.961128592491\n",
      "loss - 3171.5699560046196\n",
      "loss - 3171.337196648121\n",
      "loss - 3168.9303570389748\n",
      "loss - 3169.9253227114677\n",
      "loss - 3174.0023003816605\n",
      "loss - 3170.7359150648117\n",
      "loss - 3170.390418559313\n",
      "loss - 3170.521861076355\n",
      "loss - 3169.104436457157\n",
      "loss - 3168.3968183398247\n",
      "loss - 3170.152851343155\n",
      "loss - 3168.107354223728\n",
      "loss - 3166.0263993144035\n",
      "loss - 3167.067376971245\n",
      "loss - 3168.3913288116455\n",
      "loss - 3167.355736553669\n",
      "loss - 3165.5602772831917\n",
      "loss - 3165.872868478298\n",
      "loss - 3164.686447560787\n",
      "loss - 3167.9066123366356\n",
      "loss - 3164.4566895365715\n",
      "loss - 3166.390669643879\n",
      "loss - 3164.374293088913\n",
      "loss - 3161.752698123455\n",
      "loss - 3161.218583226204\n",
      "loss - 3161.2380088567734\n",
      "loss - 3159.205416381359\n",
      "loss - 3161.201909124851\n",
      "loss - 3160.6382759809494\n",
      "loss - 3160.2103727161884\n",
      "loss - 3158.08558344841\n",
      "loss - 3159.5554916858673\n",
      "loss - 3163.8394921422005\n",
      "loss - 3157.681647837162\n",
      "loss - 3160.6677421331406\n",
      "loss - 3157.970615029335\n",
      "loss - 3154.4098691940308\n",
      "loss - 3157.7942244410515\n",
      "loss - 3158.091039299965\n",
      "loss - 3157.0746673345566\n",
      "loss - 3158.7241482138634\n",
      "loss - 3157.0124672055244\n",
      "loss - 3153.7681078910828\n",
      "loss - 3154.7487531900406\n",
      "loss - 3155.505444765091\n",
      "loss - 3154.679200530052\n",
      "loss - 3153.3979857563972\n",
      "loss - 3153.5914444327354\n",
      "loss - 3153.284294962883\n",
      "loss - 3153.9676434993744\n",
      "loss - 3151.5729417800903\n",
      "loss - 3155.2438839673996\n",
      "loss - 3152.071441948414\n",
      "loss - 3151.6794100403786\n",
      "loss - 3151.578870475292\n",
      "loss - 3151.1152616143227\n",
      "loss - 3150.907870590687\n",
      "loss - 3147.352755010128\n",
      "loss - 3150.6939505934715\n",
      "loss - 3150.8671716451645\n",
      "loss - 3152.4546006321907\n",
      "loss - 3153.0636916160583\n",
      "loss - 3149.5952854156494\n",
      "loss - 3150.498109102249\n",
      "loss - 3146.652642428875\n",
      "loss - 3146.1065937280655\n",
      "loss - 3148.9234988093376\n",
      "loss - 3145.9653878211975\n",
      "loss - 3144.7615665495396\n",
      "loss - 3144.9851489067078\n",
      "loss - 3144.9392540454865\n",
      "loss - 3144.2181456685066\n",
      "loss - 3143.647956132889\n",
      "loss - 3146.7480271458626\n",
      "loss - 3143.113125026226\n",
      "loss - 3144.2164036035538\n",
      "loss - 3143.633102029562\n",
      "loss - 3142.568028986454\n",
      "loss - 3143.7812432050705\n",
      "loss - 3142.811682164669\n",
      "loss - 3139.4898389577866\n",
      "loss - 3140.744782447815\n",
      "loss - 3145.3330047130585\n",
      "loss - 3141.7487397789955\n",
      "loss - 3139.604028940201\n",
      "loss - 3142.352706491947\n",
      "loss - 3139.7155835926533\n",
      "loss - 3139.662171572447\n",
      "loss - 3138.0121434926987\n",
      "loss - 3136.7262375950813\n",
      "loss - 3137.01613008976\n",
      "loss - 3136.658122956753\n",
      "loss - 3136.0619872808456\n",
      "loss - 3141.7299106121063\n",
      "loss - 3135.655736207962\n",
      "loss - 3138.0857751965523\n",
      "loss - 3139.7369336485863\n",
      "loss - 3136.6534890532494\n",
      "loss - 3139.7980320453644\n",
      "loss - 3132.1478033661842\n",
      "loss - 3136.8801603913307\n",
      "loss - 3139.145927965641\n",
      "loss - 3135.3345556259155\n",
      "loss - 3133.6407494544983\n",
      "loss - 3132.657689779997\n",
      "loss - 3135.3922985494137\n",
      "loss - 3135.1128027439117\n",
      "loss - 3135.2366546094418\n",
      "loss - 3139.468783915043\n",
      "loss - 3131.7547682225704\n",
      "loss - 3135.912376642227\n",
      "loss - 3132.0145866274834\n",
      "loss - 3130.9248238801956\n",
      "loss - 3130.0035195350647\n",
      "loss - 3130.465977460146\n",
      "loss - 3130.6739971637726\n",
      "loss - 3134.1639986634254\n",
      "loss - 3132.8495660424232\n",
      "loss - 3131.9689490795135\n",
      "loss - 3132.2572925686836\n",
      "loss - 3128.9851187467575\n",
      "loss - 3127.519053131342\n",
      "loss - 3150.8388684391975\n",
      "loss - 3131.8229380249977\n",
      "loss - 3128.1853402256966\n",
      "loss - 3130.976238191128\n",
      "loss - 3127.478248000145\n",
      "loss - 3123.3334769308567\n",
      "loss - 3125.8432964086533\n",
      "loss - 3127.127523601055\n",
      "loss - 3124.257915377617\n",
      "loss - 3127.95913875103\n",
      "loss - 3124.471004843712\n",
      "loss - 3125.5460746884346\n",
      "loss - 3126.510073840618\n",
      "loss - 3122.6189134716988\n",
      "loss - 3124.546300113201\n",
      "loss - 3123.793080151081\n",
      "loss - 3122.475501000881\n",
      "loss - 3123.35044747591\n",
      "loss - 3127.724589407444\n",
      "loss - 3120.5319726467133\n",
      "loss - 3122.973196864128\n",
      "loss - 3120.259955793619\n",
      "loss - 3125.67235904932\n",
      "loss - 3123.5587754249573\n",
      "loss - 3118.6319914758205\n",
      "loss - 3120.8384453058243\n",
      "loss - 3120.443373352289\n",
      "loss - 3118.5162909328938\n",
      "loss - 3124.0598759055138\n",
      "loss - 3115.345263183117\n",
      "loss - 3120.1496911644936\n",
      "loss - 3125.3937934935093\n",
      "loss - 3119.9786008894444\n",
      "loss - 3121.0505601763725\n",
      "loss - 3124.800699234009\n",
      "loss - 3121.38308095932\n",
      "loss - 3121.603906005621\n",
      "loss - 3124.326316475868\n",
      "loss - 3122.9716477692127\n",
      "loss - 3118.8605341017246\n",
      "loss - 3124.7872309088707\n",
      "loss - 3119.337183088064\n",
      "loss - 3121.113267958164\n",
      "loss - 3117.36207818985\n",
      "loss - 3120.7515405118465\n",
      "loss - 3120.4455665647984\n",
      "loss - 3120.126744300127\n",
      "loss - 3120.016374349594\n",
      "loss - 3120.185329735279\n",
      "loss - 3116.7174169421196\n",
      "loss - 3118.867626696825\n",
      "loss - 3118.7993422448635\n",
      "loss - 3116.2316441237926\n",
      "loss - 3120.591060578823\n",
      "loss - 3121.2697839438915\n",
      "loss - 3116.4325807988644\n",
      "loss - 3114.4030328392982\n",
      "loss - 3117.381648659706\n",
      "loss - 3119.733322829008\n",
      "loss - 3119.0111742913723\n",
      "loss - 3113.5269824564457\n",
      "loss - 3116.7551542520523\n",
      "loss - 3134.513854175806\n",
      "loss - 3112.8001189231873\n",
      "loss - 3108.338906288147\n",
      "loss - 3116.850669980049\n",
      "loss - 3115.0798859596252\n",
      "loss - 3126.283907175064\n",
      "loss - 3114.680531203747\n",
      "loss - 3115.3701082766056\n",
      "loss - 3114.070282071829\n",
      "loss - 3113.2953954041004\n",
      "loss - 3110.698193013668\n",
      "loss - 3116.6297411322594\n",
      "loss - 3111.9614304304123\n",
      "loss - 3113.980424553156\n",
      "loss - 3111.103207349777\n",
      "loss - 3108.8997215628624\n",
      "loss - 3106.8126385211945\n",
      "loss - 3111.3914565443993\n",
      "loss - 3112.364188671112\n",
      "loss - 3110.535940527916\n",
      "loss - 3110.459898263216\n",
      "loss - 3111.736134380102\n",
      "loss - 3115.2249835133553\n",
      "loss - 3109.9151196181774\n",
      "loss - 3110.950361788273\n",
      "loss - 3110.0643198490143\n",
      "loss - 3109.580566674471\n",
      "loss - 3120.801301628351\n",
      "loss - 3111.0588731467724\n",
      "loss - 3118.7288352251053\n",
      "loss - 3116.5077709555626\n",
      "loss - 3112.7112299501896\n",
      "loss - 3106.523049414158\n",
      "loss - 3106.406440705061\n",
      "loss - 3112.2656711041927\n",
      "loss - 3107.0314441025257\n",
      "loss - 3108.057671159506\n",
      "loss - 3107.541376620531\n",
      "loss - 3110.331644296646\n",
      "loss - 3108.4027342796326\n",
      "loss - 3102.3063748776913\n",
      "loss - 3105.380238443613\n",
      "loss - 3106.5434244275093\n",
      "loss - 3109.2754949331284\n",
      "loss - 3109.6455233097076\n",
      "loss - 3105.5695586800575\n",
      "loss - 3105.967499434948\n",
      "loss - 3102.0816901922226\n",
      "loss - 3108.642132103443\n",
      "loss - 3105.3707791268826\n",
      "loss - 3101.738234758377\n",
      "loss - 3099.33238697052\n",
      "loss - 3100.1854135990143\n",
      "loss - 3105.63321018219\n",
      "loss - 3102.305813252926\n",
      "loss - 3102.5568586587906\n",
      "loss - 3103.3607507646084\n",
      "loss - 3105.5560480058193\n",
      "loss - 3107.072993993759\n",
      "loss - 3104.7804145514965\n",
      "loss - 3098.0139480233192\n",
      "loss - 3110.5238449275494\n",
      "loss - 3107.923398464918\n",
      "loss - 3110.623102903366\n",
      "loss - 3101.776439756155\n",
      "loss - 3102.344800978899\n",
      "loss - 3103.772537112236\n",
      "loss - 3101.4443371891975\n",
      "loss - 3108.705811023712\n",
      "loss - 3103.1387889683247\n",
      "loss - 3101.34540489316\n",
      "loss - 3110.0865057706833\n",
      "loss - 3106.555520057678\n",
      "loss - 3100.7513900995255\n",
      "loss - 3100.082050204277\n",
      "loss - 3103.6216746270657\n",
      "loss - 3099.8304119110107\n",
      "loss - 3101.477355182171\n",
      "loss - 3098.853482604027\n",
      "loss - 3108.3033388853073\n",
      "loss - 3123.821027636528\n",
      "loss - 3121.6511224508286\n",
      "loss - 3114.9789651334286\n",
      "loss - 3108.2626742124557\n",
      "loss - 3105.8154321312904\n",
      "loss - 3105.1162339150906\n",
      "loss - 3104.4717476963997\n",
      "loss - 3106.603785634041\n",
      "loss - 3099.5725049078465\n",
      "loss - 3096.69858494401\n",
      "loss - 3099.2006662487984\n",
      "loss - 3098.175990074873\n",
      "loss - 3097.6174875199795\n",
      "loss - 3112.7027514874935\n",
      "loss - 3103.583797186613\n",
      "loss - 3110.17322319746\n",
      "loss - 3105.7490387260914\n",
      "loss - 3100.2894452512264\n",
      "loss - 3097.367186129093\n",
      "loss - 3100.367834240198\n",
      "loss - 3100.3849168121815\n",
      "loss - 3102.5194457769394\n",
      "loss - 3104.952567845583\n",
      "loss - 3098.213742464781\n",
      "loss - 3098.293396383524\n",
      "loss - 3094.218077480793\n",
      "loss - 3102.8448415398598\n",
      "loss - 3099.2705168128014\n",
      "loss - 3103.0765128731728\n",
      "loss - 3099.899820238352\n",
      "loss - 3106.133506000042\n",
      "loss - 3102.3588581085205\n",
      "loss - 3094.767242729664\n",
      "loss - 3096.5639204382896\n",
      "loss - 3103.8630778193474\n",
      "loss - 3100.406559765339\n",
      "loss - 3099.107389599085\n",
      "loss - 3101.9841348826885\n",
      "loss - 3099.9151861965656\n",
      "loss - 3098.904063254595\n",
      "loss - 3101.9239808917046\n",
      "loss - 3098.4150836765766\n",
      "loss - 3103.040751069784\n",
      "loss - 3103.5809497237206\n",
      "loss - 3098.663856267929\n",
      "loss - 3095.269871175289\n",
      "loss - 3097.3352067172527\n",
      "loss - 3096.5929707586765\n",
      "loss - 3091.762148410082\n",
      "loss - 3095.523185521364\n",
      "loss - 3102.6619936823845\n",
      "loss - 3098.76249140501\n",
      "loss - 3095.329991787672\n",
      "loss - 3099.45343542099\n",
      "loss - 3092.9067457318306\n",
      "loss - 3090.712662488222\n",
      "loss - 3094.4392214119434\n",
      "loss - 3092.3912150859833\n",
      "loss - 3096.6424745321274\n",
      "loss - 3094.256771862507\n",
      "loss - 3093.950542539358\n",
      "loss - 3094.351132273674\n",
      "loss - 3097.718761205673\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(500):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for input, target in train_loader:\n",
    "        input, target = input.to('cuda'), target.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'loss - {running_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6132886675504281\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for input, target in test_loader:\n",
    "        input, target = input.to('cuda'), target.to('cuda')\n",
    "        output = torch.round(model(input))\n",
    "        all_preds.extend(output.to('cpu'))\n",
    "        all_labels.extend(target.to('cpu'))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(all_preds, all_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
