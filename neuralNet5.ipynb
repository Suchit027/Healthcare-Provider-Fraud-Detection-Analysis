{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, p1, p2):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Linear(31, 31, bias= True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(31, 31, bias= True),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p= p1),\n",
    "            nn.Linear(31, 30, bias = True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30, 30, bias= True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30, 30, bias= True),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p= p2),\n",
    "            nn.Linear(30, 25, bias= True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(25, 20, bias= True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 15, bias= True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(15, 10, bias= True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 5, bias = True),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.classify = nn.Sequential(\n",
    "            nn.Linear(5, 1, bias= True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.classify(self.features(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__()\n",
    "        self.x = torch.tensor(x.values, dtype= torch.float32)\n",
    "        self.y = torch.tensor(y.values, dtype= torch.float32)\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.x[index], self.y[index]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, ytrain, xtest, ytest = pd.read_csv('./X_train.csv', header= None, index_col = None), pd.read_csv('./y_train.csv', header = None, index_col = None), pd.read_csv('./X_test.csv', header = None, index_col = None), pd.read_csv('./y_test.csv', header = None, index_col = None)\n",
    "train_data = Data(x= xtrain, y= ytrain)\n",
    "test_data = Data(x= xtest, y= ytest)\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle= True)\n",
    "test_loader = DataLoader(test_data, batch_size= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (features): Sequential(\n",
       "    (0): Linear(in_features=31, out_features=31, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=31, out_features=31, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Dropout(p=0.3, inplace=False)\n",
       "    (5): Linear(in_features=31, out_features=30, bias=True)\n",
       "    (6): ReLU()\n",
       "    (7): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (8): ReLU()\n",
       "    (9): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout(p=0.6, inplace=False)\n",
       "    (12): Linear(in_features=30, out_features=25, bias=True)\n",
       "    (13): ReLU()\n",
       "    (14): Linear(in_features=25, out_features=20, bias=True)\n",
       "    (15): ReLU()\n",
       "    (16): Linear(in_features=20, out_features=15, bias=True)\n",
       "    (17): ReLU()\n",
       "    (18): Linear(in_features=15, out_features=10, bias=True)\n",
       "    (19): ReLU()\n",
       "    (20): Linear(in_features=10, out_features=5, bias=True)\n",
       "    (21): ReLU()\n",
       "  )\n",
       "  (classify): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=1, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network(0.3, 0.6)\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001, weight_decay= 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss - 3338.6132078170776\n",
      "loss - 3314.9166523218155\n",
      "loss - 3311.9634160995483\n",
      "loss - 3310.011078953743\n",
      "loss - 3307.3223690390587\n",
      "loss - 3303.5523953437805\n",
      "loss - 3300.8838123083115\n",
      "loss - 3300.076217651367\n",
      "loss - 3298.531846702099\n",
      "loss - 3297.758933007717\n",
      "loss - 3296.3846630454063\n",
      "loss - 3295.898630142212\n",
      "loss - 3295.540343761444\n",
      "loss - 3294.730865716934\n",
      "loss - 3293.7247482538223\n",
      "loss - 3292.9952949881554\n",
      "loss - 3292.4407187104225\n",
      "loss - 3291.575024485588\n",
      "loss - 3290.695299744606\n",
      "loss - 3290.5020881295204\n",
      "loss - 3289.237719833851\n",
      "loss - 3288.506616473198\n",
      "loss - 3288.746652305126\n",
      "loss - 3288.1186366677284\n",
      "loss - 3287.765330016613\n",
      "loss - 3287.7912868261337\n",
      "loss - 3286.9779269099236\n",
      "loss - 3286.275299370289\n",
      "loss - 3285.742747604847\n",
      "loss - 3285.2451055049896\n",
      "loss - 3285.298554599285\n",
      "loss - 3284.931565821171\n",
      "loss - 3283.9746918082237\n",
      "loss - 3284.5658054351807\n",
      "loss - 3284.208101928234\n",
      "loss - 3282.731676697731\n",
      "loss - 3283.4207869172096\n",
      "loss - 3283.208724975586\n",
      "loss - 3282.538392364979\n",
      "loss - 3282.0715876221657\n",
      "loss - 3282.0077694654465\n",
      "loss - 3280.906843960285\n",
      "loss - 3280.930048763752\n",
      "loss - 3280.4955411553383\n",
      "loss - 3279.078606903553\n",
      "loss - 3278.828653872013\n",
      "loss - 3278.175735473633\n",
      "loss - 3277.623182475567\n",
      "loss - 3277.1092846393585\n",
      "loss - 3276.874738574028\n",
      "loss - 3276.6888332366943\n",
      "loss - 3275.409111022949\n",
      "loss - 3275.455753862858\n",
      "loss - 3274.492897629738\n",
      "loss - 3274.618373990059\n",
      "loss - 3274.3000849485397\n",
      "loss - 3273.8900574445724\n",
      "loss - 3272.3914444446564\n",
      "loss - 3272.112085223198\n",
      "loss - 3272.193876504898\n",
      "loss - 3272.0205632448196\n",
      "loss - 3272.61081135273\n",
      "loss - 3272.140920162201\n",
      "loss - 3270.0436958670616\n",
      "loss - 3270.1022378206253\n",
      "loss - 3268.5962896943092\n",
      "loss - 3268.1013387441635\n",
      "loss - 3268.0180963277817\n",
      "loss - 3267.5213508605957\n",
      "loss - 3266.9557766914368\n",
      "loss - 3268.007617533207\n",
      "loss - 3267.2597126960754\n",
      "loss - 3266.4104620814323\n",
      "loss - 3266.372803926468\n",
      "loss - 3266.255779027939\n",
      "loss - 3265.632383108139\n",
      "loss - 3265.500402212143\n",
      "loss - 3264.8537610173225\n",
      "loss - 3264.3393784165382\n",
      "loss - 3264.782721579075\n",
      "loss - 3264.1613469719887\n",
      "loss - 3263.020569741726\n",
      "loss - 3262.721413552761\n",
      "loss - 3262.8225880861282\n",
      "loss - 3261.3155881762505\n",
      "loss - 3261.3467693924904\n",
      "loss - 3260.2557862997055\n",
      "loss - 3259.4249525666237\n",
      "loss - 3261.2356371879578\n",
      "loss - 3258.677092075348\n",
      "loss - 3258.253348529339\n",
      "loss - 3258.3016579151154\n",
      "loss - 3258.1484275460243\n",
      "loss - 3258.2965962290764\n",
      "loss - 3258.148250937462\n",
      "loss - 3258.1769309043884\n",
      "loss - 3256.332349359989\n",
      "loss - 3256.162455737591\n",
      "loss - 3255.285588681698\n",
      "loss - 3255.049026429653\n",
      "loss - 3254.3472650647163\n",
      "loss - 3253.5040868520737\n",
      "loss - 3253.5886602401733\n",
      "loss - 3254.4096524119377\n",
      "loss - 3251.9123461842537\n",
      "loss - 3253.360442698002\n",
      "loss - 3252.096842110157\n",
      "loss - 3252.7464364767075\n",
      "loss - 3251.6005204916\n",
      "loss - 3251.4479308128357\n",
      "loss - 3251.0250964164734\n",
      "loss - 3248.6230497956276\n",
      "loss - 3249.677289366722\n",
      "loss - 3248.8369930386543\n",
      "loss - 3248.0475345253944\n",
      "loss - 3247.3955116271973\n",
      "loss - 3247.7894181609154\n",
      "loss - 3247.047097027302\n",
      "loss - 3249.0372390151024\n",
      "loss - 3247.308966457844\n",
      "loss - 3247.14045971632\n",
      "loss - 3245.341054201126\n",
      "loss - 3245.8093317747116\n",
      "loss - 3245.90647315979\n",
      "loss - 3244.129718363285\n",
      "loss - 3244.2441168427467\n",
      "loss - 3244.256813108921\n",
      "loss - 3241.8199152350426\n",
      "loss - 3242.162229657173\n",
      "loss - 3242.7773302197456\n",
      "loss - 3241.738904416561\n",
      "loss - 3242.453926026821\n",
      "loss - 3242.3669167757034\n",
      "loss - 3240.927971303463\n",
      "loss - 3239.609656393528\n",
      "loss - 3239.637493610382\n",
      "loss - 3240.20522660017\n",
      "loss - 3240.0127826929092\n",
      "loss - 3240.5275846123695\n",
      "loss - 3238.004632651806\n",
      "loss - 3239.9782242774963\n",
      "loss - 3239.1731014847755\n",
      "loss - 3236.6591859459877\n",
      "loss - 3237.9126893877983\n",
      "loss - 3235.904989719391\n",
      "loss - 3236.756175816059\n",
      "loss - 3236.8139376044273\n",
      "loss - 3238.5924728512764\n",
      "loss - 3235.629792511463\n",
      "loss - 3233.7070021629333\n",
      "loss - 3235.4660969376564\n",
      "loss - 3234.488568544388\n",
      "loss - 3232.2673560380936\n",
      "loss - 3234.567657291889\n",
      "loss - 3234.752117872238\n",
      "loss - 3235.0922525525093\n",
      "loss - 3232.19733697176\n",
      "loss - 3233.084136068821\n",
      "loss - 3234.316211760044\n",
      "loss - 3232.424089848995\n",
      "loss - 3232.022475898266\n",
      "loss - 3230.244025528431\n",
      "loss - 3231.5886115431786\n",
      "loss - 3234.951391160488\n",
      "loss - 3231.144152879715\n",
      "loss - 3230.0008103847504\n",
      "loss - 3228.62230104208\n",
      "loss - 3231.850065469742\n",
      "loss - 3231.2431535720825\n",
      "loss - 3229.4898339509964\n",
      "loss - 3228.910190999508\n",
      "loss - 3233.138249337673\n",
      "loss - 3229.6664438843727\n",
      "loss - 3227.731930732727\n",
      "loss - 3229.7518615722656\n",
      "loss - 3229.882715821266\n",
      "loss - 3227.564558148384\n",
      "loss - 3232.9895012378693\n",
      "loss - 3227.8120403289795\n",
      "loss - 3225.9790254831314\n",
      "loss - 3226.8757945895195\n",
      "loss - 3227.128245830536\n",
      "loss - 3226.3919152617455\n",
      "loss - 3229.889086663723\n",
      "loss - 3227.5106738209724\n",
      "loss - 3227.3457698225975\n",
      "loss - 3227.8238620758057\n",
      "loss - 3227.9760479331017\n",
      "loss - 3226.6910622119904\n",
      "loss - 3227.208925127983\n",
      "loss - 3229.639907181263\n",
      "loss - 3225.205384373665\n",
      "loss - 3223.7320655584335\n",
      "loss - 3224.172381222248\n",
      "loss - 3230.917365729809\n",
      "loss - 3225.1288734674454\n",
      "loss - 3226.058256328106\n",
      "loss - 3222.607680261135\n",
      "loss - 3225.658623754978\n",
      "loss - 3224.605635523796\n",
      "loss - 3222.90027064085\n",
      "loss - 3223.250929415226\n",
      "loss - 3224.3909722566605\n",
      "loss - 3222.2212330698967\n",
      "loss - 3227.092920124531\n",
      "loss - 3224.1852439641953\n",
      "loss - 3220.0160155296326\n",
      "loss - 3222.6866107583046\n",
      "loss - 3224.410014152527\n",
      "loss - 3221.9255229234695\n",
      "loss - 3220.6508915424347\n",
      "loss - 3218.992329418659\n",
      "loss - 3217.2921820878983\n",
      "loss - 3221.793920457363\n",
      "loss - 3217.907983005047\n",
      "loss - 3219.400704741478\n",
      "loss - 3218.8750606775284\n",
      "loss - 3220.614882826805\n",
      "loss - 3217.794735610485\n",
      "loss - 3220.0179809331894\n",
      "loss - 3222.3058229088783\n",
      "loss - 3217.1622173190117\n",
      "loss - 3217.3614993691444\n",
      "loss - 3218.816421866417\n",
      "loss - 3220.1658979058266\n",
      "loss - 3217.6484884023666\n",
      "loss - 3216.0860741734505\n",
      "loss - 3214.093217253685\n",
      "loss - 3216.2426332831383\n",
      "loss - 3215.3055598139763\n",
      "loss - 3217.127491056919\n",
      "loss - 3217.3917511701584\n",
      "loss - 3217.336625814438\n",
      "loss - 3217.192964911461\n",
      "loss - 3213.6611145734787\n",
      "loss - 3213.529303789139\n",
      "loss - 3214.9637873768806\n",
      "loss - 3218.5214958786964\n",
      "loss - 3215.593804180622\n",
      "loss - 3212.6297671198845\n",
      "loss - 3211.4422733187675\n",
      "loss - 3211.318615615368\n",
      "loss - 3211.30874311924\n",
      "loss - 3214.498075544834\n",
      "loss - 3217.458261847496\n",
      "loss - 3213.5716478824615\n",
      "loss - 3213.561311662197\n",
      "loss - 3211.2489570379257\n",
      "loss - 3212.741769492626\n",
      "loss - 3211.847432434559\n",
      "loss - 3209.9639666080475\n",
      "loss - 3209.3060827851295\n",
      "loss - 3213.723478257656\n",
      "loss - 3208.3890330791473\n",
      "loss - 3208.721541941166\n",
      "loss - 3207.4022004008293\n",
      "loss - 3209.3610421419144\n",
      "loss - 3211.545030593872\n",
      "loss - 3205.7735626101494\n",
      "loss - 3208.4494947195053\n",
      "loss - 3207.035039126873\n",
      "loss - 3209.8905261158943\n",
      "loss - 3205.7746705412865\n",
      "loss - 3208.166257560253\n",
      "loss - 3208.7220634818077\n",
      "loss - 3206.1182382702827\n",
      "loss - 3207.6025812625885\n",
      "loss - 3210.9838891625404\n",
      "loss - 3222.766671836376\n",
      "loss - 3223.1059671640396\n",
      "loss - 3210.023809015751\n",
      "loss - 3209.529798269272\n",
      "loss - 3207.6754444241524\n",
      "loss - 3203.346624135971\n",
      "loss - 3203.6027405261993\n",
      "loss - 3205.343243956566\n",
      "loss - 3204.2931005954742\n",
      "loss - 3205.5794231295586\n",
      "loss - 3202.8033311367035\n",
      "loss - 3204.227424323559\n",
      "loss - 3204.17220133543\n",
      "loss - 3202.9974358081818\n",
      "loss - 3204.1752898693085\n",
      "loss - 3204.4196639060974\n",
      "loss - 3206.9213522672653\n",
      "loss - 3202.2615420222282\n",
      "loss - 3204.5350155234337\n",
      "loss - 3203.232749938965\n",
      "loss - 3202.246489584446\n",
      "loss - 3204.495346367359\n",
      "loss - 3205.4389796853065\n",
      "loss - 3204.618305981159\n",
      "loss - 3202.899591386318\n",
      "loss - 3205.8441187143326\n",
      "loss - 3204.316363990307\n",
      "loss - 3206.1921131014824\n",
      "loss - 3202.694415509701\n",
      "loss - 3202.4640126228333\n",
      "loss - 3205.968593776226\n",
      "loss - 3202.5819932222366\n",
      "loss - 3205.0954264998436\n",
      "loss - 3204.994404196739\n",
      "loss - 3199.8305132985115\n",
      "loss - 3202.659047603607\n",
      "loss - 3203.5357713103294\n",
      "loss - 3201.1056582927704\n",
      "loss - 3206.789228081703\n",
      "loss - 3200.9463802576065\n",
      "loss - 3200.4902304410934\n",
      "loss - 3199.69753664732\n",
      "loss - 3200.561604976654\n",
      "loss - 3202.456816136837\n",
      "loss - 3202.2682890295982\n",
      "loss - 3206.2740126252174\n",
      "loss - 3201.9791491627693\n",
      "loss - 3205.868755221367\n",
      "loss - 3203.221935927868\n",
      "loss - 3198.765849709511\n",
      "loss - 3200.330628693104\n",
      "loss - 3198.5684002637863\n",
      "loss - 3200.6941536664963\n",
      "loss - 3200.203530550003\n",
      "loss - 3198.5917903780937\n",
      "loss - 3201.372433960438\n",
      "loss - 3197.7816212773323\n",
      "loss - 3198.806811094284\n",
      "loss - 3201.502168774605\n",
      "loss - 3200.073209106922\n",
      "loss - 3198.6195061206818\n",
      "loss - 3198.284518957138\n",
      "loss - 3200.434008717537\n",
      "loss - 3196.412084341049\n",
      "loss - 3197.157178938389\n",
      "loss - 3194.568447291851\n",
      "loss - 3197.3981300592422\n",
      "loss - 3196.760115802288\n",
      "loss - 3196.6916496157646\n",
      "loss - 3196.4067317843437\n",
      "loss - 3194.3748936653137\n",
      "loss - 3200.409693777561\n",
      "loss - 3198.4538056850433\n",
      "loss - 3198.3055543899536\n",
      "loss - 3199.087868273258\n",
      "loss - 3199.054256260395\n",
      "loss - 3199.140548825264\n",
      "loss - 3197.749648153782\n",
      "loss - 3197.964874982834\n",
      "loss - 3194.7857833504677\n",
      "loss - 3197.5234293341637\n",
      "loss - 3200.2587312459946\n",
      "loss - 3195.943215250969\n",
      "loss - 3199.0908542871475\n",
      "loss - 3198.7280297875404\n",
      "loss - 3198.137819290161\n",
      "loss - 3198.160239338875\n",
      "loss - 3195.015118122101\n",
      "loss - 3198.668793797493\n",
      "loss - 3198.5268454551697\n",
      "loss - 3194.460275709629\n",
      "loss - 3193.8620641231537\n",
      "loss - 3197.096023797989\n",
      "loss - 3195.7012854218483\n",
      "loss - 3198.9752292633057\n",
      "loss - 3199.6545622348785\n",
      "loss - 3192.724482357502\n",
      "loss - 3196.6875188946724\n",
      "loss - 3200.3039525151253\n",
      "loss - 3197.787406384945\n",
      "loss - 3198.939189374447\n",
      "loss - 3193.7534607052803\n",
      "loss - 3197.494170129299\n",
      "loss - 3198.2681745886803\n",
      "loss - 3194.902968585491\n",
      "loss - 3196.5212550759315\n",
      "loss - 3194.9014407396317\n",
      "loss - 3195.378009557724\n",
      "loss - 3197.178628921509\n",
      "loss - 3195.4422267079353\n",
      "loss - 3198.3839460611343\n",
      "loss - 3194.616844713688\n",
      "loss - 3199.50285166502\n",
      "loss - 3196.284429848194\n",
      "loss - 3198.9637730121613\n",
      "loss - 3196.268998682499\n",
      "loss - 3194.4025389552116\n",
      "loss - 3194.8130538463593\n",
      "loss - 3198.284441947937\n",
      "loss - 3198.79300814867\n",
      "loss - 3195.326203942299\n",
      "loss - 3195.224851310253\n",
      "loss - 3196.919168174267\n",
      "loss - 3193.7531847953796\n",
      "loss - 3198.2876585125923\n",
      "loss - 3192.4736382365227\n",
      "loss - 3197.7540587186813\n",
      "loss - 3196.600066781044\n",
      "loss - 3193.8007387518883\n",
      "loss - 3192.3787412643433\n",
      "loss - 3193.2275191545486\n",
      "loss - 3191.8071531653404\n",
      "loss - 3192.0532653927803\n",
      "loss - 3193.1854657530785\n",
      "loss - 3195.144386291504\n",
      "loss - 3192.14023655653\n",
      "loss - 3193.408038556576\n",
      "loss - 3192.237740814686\n",
      "loss - 3192.3595727086067\n",
      "loss - 3188.6948085427284\n",
      "loss - 3193.183694422245\n",
      "loss - 3191.006334245205\n",
      "loss - 3190.3771997094154\n",
      "loss - 3193.532742381096\n",
      "loss - 3188.4879537820816\n",
      "loss - 3189.424612402916\n",
      "loss - 3190.026198387146\n",
      "loss - 3190.4886839985847\n",
      "loss - 3188.0332027077675\n",
      "loss - 3193.357557296753\n",
      "loss - 3187.916083216667\n",
      "loss - 3189.4238063693047\n",
      "loss - 3192.1218202114105\n",
      "loss - 3192.3443933725357\n",
      "loss - 3189.6596111655235\n",
      "loss - 3188.186194896698\n",
      "loss - 3195.2435705065727\n",
      "loss - 3192.1352581977844\n",
      "loss - 3187.5016933083534\n",
      "loss - 3194.1762596964836\n",
      "loss - 3190.9201650619507\n",
      "loss - 3190.14610555768\n",
      "loss - 3191.6582579016685\n",
      "loss - 3191.1165130138397\n",
      "loss - 3190.4574897289276\n",
      "loss - 3190.65330350399\n",
      "loss - 3192.5238304138184\n",
      "loss - 3188.704739153385\n",
      "loss - 3190.132345199585\n",
      "loss - 3186.6467299461365\n",
      "loss - 3189.6113018989563\n",
      "loss - 3187.0896438360214\n",
      "loss - 3191.9402725696564\n",
      "loss - 3189.9178131222725\n",
      "loss - 3185.6474943757057\n",
      "loss - 3186.112937271595\n",
      "loss - 3187.119792163372\n",
      "loss - 3189.53301101923\n",
      "loss - 3190.6006913781166\n",
      "loss - 3187.6447988152504\n",
      "loss - 3187.7924317121506\n",
      "loss - 3190.2789048552513\n",
      "loss - 3194.537485420704\n",
      "loss - 3189.0898636579514\n",
      "loss - 3187.596283197403\n",
      "loss - 3186.043056666851\n",
      "loss - 3187.8854850530624\n",
      "loss - 3186.2139762043953\n",
      "loss - 3187.1755657196045\n",
      "loss - 3191.450898230076\n",
      "loss - 3187.3816447257996\n",
      "loss - 3186.911028265953\n",
      "loss - 3185.210426926613\n",
      "loss - 3185.930356681347\n",
      "loss - 3183.700226187706\n",
      "loss - 3183.6174711585045\n",
      "loss - 3187.0171661376953\n",
      "loss - 3189.0440254211426\n",
      "loss - 3187.411907196045\n",
      "loss - 3186.6726370453835\n",
      "loss - 3188.3894262313843\n",
      "loss - 3192.8798720240593\n",
      "loss - 3193.465907216072\n",
      "loss - 3189.18457698822\n",
      "loss - 3186.3299046754837\n",
      "loss - 3187.8125562667847\n",
      "loss - 3184.0929010510445\n",
      "loss - 3187.7796008586884\n",
      "loss - 3184.9413667321205\n",
      "loss - 3188.422026693821\n",
      "loss - 3188.3064999580383\n",
      "loss - 3188.336250424385\n",
      "loss - 3188.6702115535736\n",
      "loss - 3185.4458606243134\n",
      "loss - 3183.353318095207\n",
      "loss - 3180.8374260663986\n",
      "loss - 3184.49224370718\n",
      "loss - 3184.566149711609\n",
      "loss - 3189.1966513991356\n",
      "loss - 3185.899800002575\n",
      "loss - 3184.357392668724\n",
      "loss - 3185.68872320652\n",
      "loss - 3183.603744506836\n",
      "loss - 3182.266280412674\n",
      "loss - 3185.3004829883575\n",
      "loss - 3179.4824661016464\n",
      "loss - 3179.5593581199646\n",
      "loss - 3182.1218860149384\n",
      "loss - 3178.913079023361\n",
      "loss - 3182.5294191241264\n",
      "loss - 3183.6981430649757\n",
      "loss - 3185.250372827053\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(500):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for input, target in train_loader:\n",
    "        input, target = input.to('cuda'), target.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'loss - {running_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6071441367202894\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for input, target in test_loader:\n",
    "        input, target = input.to('cuda'), target.to('cuda')\n",
    "        output = torch.round(model(input))\n",
    "        all_preds.extend(output.to('cpu'))\n",
    "        all_labels.extend(target.to('cpu'))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(all_preds, all_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
