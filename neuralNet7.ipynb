{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, p1, p2, p3):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Linear(31, 70, bias= True),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(70, 70, bias= True),\n",
    "            nn.SiLU(),\n",
    "            nn.BatchNorm1d(70),\n",
    "            nn.Dropout(p = p1),\n",
    "            nn.Linear(70, 65, bias = True),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(65, 60, bias= True),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(60, 60, bias= True),\n",
    "            nn.SiLU(),\n",
    "            nn.BatchNorm1d(60),\n",
    "            nn.Dropout(p= p2),\n",
    "            nn.Linear(60, 55, bias= True),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(55, 50, bias= True),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(50, 45, bias= True),\n",
    "            nn.SiLU(),\n",
    "            nn.BatchNorm1d(45),\n",
    "            nn.Dropout(p= p3),\n",
    "            nn.Linear(45, 40, bias= True),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(40, 35, bias = True),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(35, 25, bias = True),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(25, 20, bias = True),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(20, 15, bias = True),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(15, 10, bias = True),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(10, 5, bias = True)\n",
    "        )\n",
    "        self.classify = nn.Sequential(\n",
    "            nn.Linear(5, 1, bias= True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.classify(self.features(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__()\n",
    "        self.x = torch.tensor(x.values, dtype= torch.float32)\n",
    "        self.y = torch.tensor(y.values, dtype= torch.float32)\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.x[index], self.y[index]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, ytrain, xtest, ytest = pd.read_csv('./X_train.csv', header= None, index_col = None), pd.read_csv('./y_train.csv', header = None, index_col = None), pd.read_csv('./X_test.csv', header = None, index_col = None), pd.read_csv('./y_test.csv', header = None, index_col = None)\n",
    "train_data = Data(x= xtrain, y= ytrain)\n",
    "test_data = Data(x= xtest, y= ytest)\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle= True)\n",
    "test_loader = DataLoader(test_data, batch_size= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (features): Sequential(\n",
       "    (0): Linear(in_features=31, out_features=70, bias=True)\n",
       "    (1): SiLU()\n",
       "    (2): Linear(in_features=70, out_features=70, bias=True)\n",
       "    (3): SiLU()\n",
       "    (4): BatchNorm1d(70, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): Dropout(p=0.3, inplace=False)\n",
       "    (6): Linear(in_features=70, out_features=65, bias=True)\n",
       "    (7): SiLU()\n",
       "    (8): Linear(in_features=65, out_features=60, bias=True)\n",
       "    (9): SiLU()\n",
       "    (10): Linear(in_features=60, out_features=60, bias=True)\n",
       "    (11): SiLU()\n",
       "    (12): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): Dropout(p=0.4, inplace=False)\n",
       "    (14): Linear(in_features=60, out_features=55, bias=True)\n",
       "    (15): SiLU()\n",
       "    (16): Linear(in_features=55, out_features=50, bias=True)\n",
       "    (17): SiLU()\n",
       "    (18): Linear(in_features=50, out_features=45, bias=True)\n",
       "    (19): SiLU()\n",
       "    (20): BatchNorm1d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (21): Dropout(p=0.5, inplace=False)\n",
       "    (22): Linear(in_features=45, out_features=40, bias=True)\n",
       "    (23): SiLU()\n",
       "    (24): Linear(in_features=40, out_features=35, bias=True)\n",
       "    (25): SiLU()\n",
       "    (26): Linear(in_features=35, out_features=25, bias=True)\n",
       "    (27): SiLU()\n",
       "    (28): Linear(in_features=25, out_features=20, bias=True)\n",
       "    (29): SiLU()\n",
       "    (30): Linear(in_features=20, out_features=15, bias=True)\n",
       "    (31): SiLU()\n",
       "    (32): Linear(in_features=15, out_features=10, bias=True)\n",
       "    (33): SiLU()\n",
       "    (34): Linear(in_features=10, out_features=5, bias=True)\n",
       "  )\n",
       "  (classify): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=1, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network(0.3, 0.4, 0.5)\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "# learning rate decreased by power of 10\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001, weight_decay= 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 0 loss - 3333.8497000336647\n",
      "Epoch - 1 loss - 3307.996366381645\n",
      "Epoch - 2 loss - 3305.3811868429184\n",
      "Epoch - 3 loss - 3303.3021935224533\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m output = model(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m      9\u001b[39m loss = criterion(output, target)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m optimizer.step()\n\u001b[32m     12\u001b[39m running_loss_trian += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Suchit\\Deep-Learning\\venv\\Lib\\site-packages\\torch\\_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Suchit\\Deep-Learning\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Suchit\\Deep-Learning\\venv\\Lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "loss_list_train, loss_list_val = [], []\n",
    "for epoch in range(1400):\n",
    "    model.train()\n",
    "    running_loss_trian, running_loss_val = 0.0, 0.0\n",
    "    for input, target in train_loader:\n",
    "        input, target = input.to('cuda'), target.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss_trian += loss.item()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for input, target in test_loader:\n",
    "            input, target = input.to('cuda'), target.to('cuda')\n",
    "            output = torch.round(model(input))\n",
    "            loss = criterion(output, target)\n",
    "            running_loss_val += loss.item()\n",
    "    loss_list_train.append(running_loss_trian / len(train_loader))\n",
    "    loss_list_val.append(running_loss_val / len(test_loader))\n",
    "    print(f'Epoch - {epoch} loss - {running_loss_trian}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss_list_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m fig = plt.figure()\n\u001b[32m      3\u001b[39m ax = fig.add_axes([\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m plt.plot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mloss_list_train\u001b[49m)), loss_list_train, color= \u001b[33m'\u001b[39m\u001b[33mred\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# plt.plot(range(len(ll_val)), ll_val, color = 'blue')\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'loss_list_train' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAr4AAAIRCAYAAACszb5OAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAH/tJREFUeJzt3X9s1fW9+PEXrfZUM1vxcik/bh1Xd53bVHAgvdUZ49K7Jhp2+eNmXF2AS/xx3bjG0dw7QZTOuVGuVw3JxBGZXvfHvLAZNcsgeF3vyOLsDRnQxF1B49DBXdYKd9eWixuV9vP9Y1n37fghp7QFfD0eyfmDt+/3+byPb4lPP55+GFcURREAAPABV3GqNwAAAGNB+AIAkILwBQAgBeELAEAKwhcAgBSELwAAKQhfAABSEL4AAKQgfAEASEH4AgCQQtnh++Mf/zjmzJkTU6ZMiXHjxsXzzz//vmu2bNkSn/zkJ6NUKsVHPvKReOqpp4axVQAAGL6yw/fgwYMxffr0WLNmzQnNf/PNN+PGG2+M66+/Pjo7O+NLX/pS3HrrrfHCCy+UvVkAABiucUVRFMNePG5cPPfcczF37txjzrn77rtj48aN8bOf/Wxw7G//9m/jnXfeic2bNw/30gAAUJazRvsCHR0d0dTUNGSsubk5vvSlLx1zzaFDh+LQoUODvx4YGIhf//rX8Sd/8icxbty40doqAACniaIo4sCBAzFlypSoqBiZH0sb9fDt6uqKurq6IWN1dXXR29sbv/nNb+Kcc845Yk1bW1vcf//9o701AABOc3v37o0/+7M/G5H3GvXwHY5ly5ZFS0vL4K97enriwgsvjL1790ZNTc0p3BkAAGOht7c36uvr47zzzhux9xz18J00aVJ0d3cPGevu7o6ampqj3u2NiCiVSlEqlY4Yr6mpEb4AAImM5NdcR/05vo2NjdHe3j5k7MUXX4zGxsbRvjQAAAwqO3z/7//+Lzo7O6OzszMifve4ss7OztizZ09E/O5rCgsWLBicf8cdd8Tu3bvjy1/+cuzatSsee+yx+O53vxtLliwZmU8AAAAnoOzw/elPfxpXXnllXHnllRER0dLSEldeeWWsWLEiIiJ+9atfDUZwRMSf//mfx8aNG+PFF1+M6dOnx8MPPxzf+ta3orm5eYQ+AgAAvL+Teo7vWOnt7Y3a2tro6enxHV8AgARGo/9G/Tu+AABwOhC+AACkIHwBAEhB+AIAkILwBQAgBeELAEAKwhcAgBSELwAAKQhfAABSEL4AAKQgfAEASEH4AgCQgvAFACAF4QsAQArCFwCAFIQvAAApCF8AAFIQvgAApCB8AQBIQfgCAJCC8AUAIAXhCwBACsIXAIAUhC8AACkIXwAAUhC+AACkIHwBAEhB+AIAkILwBQAgBeELAEAKwhcAgBSELwAAKQhfAABSEL4AAKQgfAEASEH4AgCQgvAFACAF4QsAQArCFwCAFIQvAAApCF8AAFIQvgAApCB8AQBIQfgCAJCC8AUAIAXhCwBACsIXAIAUhC8AACkIXwAAUhC+AACkIHwBAEhB+AIAkILwBQAgBeELAEAKwhcAgBSELwAAKQhfAABSEL4AAKQgfAEASEH4AgCQgvAFACAF4QsAQArCFwCAFIQvAAApCF8AAFIQvgAApCB8AQBIQfgCAJCC8AUAIAXhCwBACsIXAIAUhC8AACkIXwAAUhC+AACkIHwBAEhB+AIAkILwBQAgBeELAEAKwhcAgBSELwAAKQhfAABSEL4AAKQgfAEASEH4AgCQgvAFACCFYYXvmjVrYtq0aVFdXR0NDQ2xdevW485fvXp1fPSjH41zzjkn6uvrY8mSJfHb3/52WBsGAIDhKDt8N2zYEC0tLdHa2hrbt2+P6dOnR3Nzc7z99ttHnf/000/H0qVLo7W1NXbu3BlPPPFEbNiwIe65556T3jwAAJyossP3kUceidtuuy0WLVoUH//4x2Pt2rVx7rnnxpNPPnnU+S+//HJcc801cfPNN8e0adPiM5/5TNx0003ve5cYAABGUlnh29fXF9u2bYumpqY/vEFFRTQ1NUVHR8dR11x99dWxbdu2wdDdvXt3bNq0KW644YZjXufQoUPR29s75AUAACfjrHIm79+/P/r7+6Ourm7IeF1dXezateuoa26++ebYv39/fOpTn4qiKOLw4cNxxx13HPerDm1tbXH//feXszUAADiuUX+qw5YtW2LlypXx2GOPxfbt2+PZZ5+NjRs3xgMPPHDMNcuWLYuenp7B1969e0d7mwAAfMCVdcd3woQJUVlZGd3d3UPGu7u7Y9KkSUddc99998X8+fPj1ltvjYiIyy+/PA4ePBi33357LF++PCoqjmzvUqkUpVKpnK0BAMBxlXXHt6qqKmbOnBnt7e2DYwMDA9He3h6NjY1HXfPuu+8eEbeVlZUREVEURbn7BQCAYSnrjm9EREtLSyxcuDBmzZoVs2fPjtWrV8fBgwdj0aJFERGxYMGCmDp1arS1tUVExJw5c+KRRx6JK6+8MhoaGuKNN96I++67L+bMmTMYwAAAMNrKDt958+bFvn37YsWKFdHV1RUzZsyIzZs3D/7A2549e4bc4b333ntj3Lhxce+998Yvf/nL+NM//dOYM2dOfP3rXx+5TwEAAO9jXHEGfN+gt7c3amtro6enJ2pqak71dgAAGGWj0X+j/lQHAAA4HQhfAABSEL4AAKQgfAEASEH4AgCQgvAFACAF4QsAQArCFwCAFIQvAAApCF8AAFIQvgAApCB8AQBIQfgCAJCC8AUAIAXhCwBACsIXAIAUhC8AACkIXwAAUhC+AACkIHwBAEhB+AIAkILwBQAgBeELAEAKwhcAgBSELwAAKQhfAABSEL4AAKQgfAEASEH4AgCQgvAFACAF4QsAQArCFwCAFIQvAAApCF8AAFIQvgAApCB8AQBIQfgCAJCC8AUAIAXhCwBACsIXAIAUhC8AACkIXwAAUhC+AACkIHwBAEhB+AIAkILwBQAgBeELAEAKwhcAgBSELwAAKQhfAABSEL4AAKQgfAEASEH4AgCQgvAFACAF4QsAQArCFwCAFIQvAAApCF8AAFIQvgAApCB8AQBIQfgCAJCC8AUAIAXhCwBACsIXAIAUhC8AACkIXwAAUhC+AACkIHwBAEhB+AIAkILwBQAgBeELAEAKwhcAgBSELwAAKQhfAABSEL4AAKQgfAEASEH4AgCQgvAFACAF4QsAQArCFwCAFIQvAAApCF8AAFIQvgAApCB8AQBIQfgCAJDCsMJ3zZo1MW3atKiuro6GhobYunXrcee/8847sXjx4pg8eXKUSqW45JJLYtOmTcPaMAAADMdZ5S7YsGFDtLS0xNq1a6OhoSFWr14dzc3N8dprr8XEiROPmN/X1xd/9Vd/FRMnToxnnnkmpk6dGr/4xS/i/PPPH4n9AwDACRlXFEVRzoKGhoa46qqr4tFHH42IiIGBgaivr48777wzli5desT8tWvXxr/8y7/Erl274uyzzx7WJnt7e6O2tjZ6enqipqZmWO8BAMCZYzT6r6yvOvT19cW2bduiqanpD29QURFNTU3R0dFx1DXf//73o7GxMRYvXhx1dXVx2WWXxcqVK6O/v/+Y1zl06FD09vYOeQEAwMkoK3z3798f/f39UVdXN2S8rq4uurq6jrpm9+7d8cwzz0R/f39s2rQp7rvvvnj44Yfja1/72jGv09bWFrW1tYOv+vr6crYJAABHGPWnOgwMDMTEiRPj8ccfj5kzZ8a8efNi+fLlsXbt2mOuWbZsWfT09Ay+9u7dO9rbBADgA66sH26bMGFCVFZWRnd395Dx7u7umDRp0lHXTJ48Oc4+++yorKwcHPvYxz4WXV1d0dfXF1VVVUesKZVKUSqVytkaAAAcV1l3fKuqqmLmzJnR3t4+ODYwMBDt7e3R2Nh41DXXXHNNvPHGGzEwMDA49vrrr8fkyZOPGr0AADAayv6qQ0tLS6xbty6+/e1vx86dO+MLX/hCHDx4MBYtWhQREQsWLIhly5YNzv/CF74Qv/71r+Ouu+6K119/PTZu3BgrV66MxYsXj9ynAACA91H2c3znzZsX+/btixUrVkRXV1fMmDEjNm/ePPgDb3v27ImKij/0dH19fbzwwguxZMmSuOKKK2Lq1Klx1113xd133z1ynwIAAN5H2c/xPRU8xxcAIJdT/hxfAAA4UwlfAABSEL4AAKQgfAEASEH4AgCQgvAFACAF4QsAQArCFwCAFIQvAAApCF8AAFIQvgAApCB8AQBIQfgCAJCC8AUAIAXhCwBACsIXAIAUhC8AACkIXwAAUhC+AACkIHwBAEhB+AIAkILwBQAgBeELAEAKwhcAgBSELwAAKQhfAABSEL4AAKQgfAEASEH4AgCQgvAFACAF4QsAQArCFwCAFIQvAAApCF8AAFIQvgAApCB8AQBIQfgCAJCC8AUAIAXhCwBACsIXAIAUhC8AACkIXwAAUhC+AACkIHwBAEhB+AIAkILwBQAgBeELAEAKwhcAgBSELwAAKQhfAABSEL4AAKQgfAEASEH4AgCQgvAFACAF4QsAQArCFwCAFIQvAAApCF8AAFIQvgAApCB8AQBIQfgCAJCC8AUAIAXhCwBACsIXAIAUhC8AACkIXwAAUhC+AACkIHwBAEhB+AIAkILwBQAgBeELAEAKwhcAgBSELwAAKQhfAABSEL4AAKQgfAEASEH4AgCQgvAFACAF4QsAQArCFwCAFIQvAAApCF8AAFIQvgAApCB8AQBIQfgCAJDCsMJ3zZo1MW3atKiuro6GhobYunXrCa1bv359jBs3LubOnTucywIAwLCVHb4bNmyIlpaWaG1tje3bt8f06dOjubk53n777eOue+utt+If//Ef49prrx32ZgEAYLjKDt9HHnkkbrvttli0aFF8/OMfj7Vr18a5554bTz755DHX9Pf3x+c///m4//7746KLLjqpDQMAwHCUFb59fX2xbdu2aGpq+sMbVFREU1NTdHR0HHPdV7/61Zg4cWLccsstJ3SdQ4cORW9v75AXAACcjLLCd//+/dHf3x91dXVDxuvq6qKrq+uoa1566aV44oknYt26dSd8nba2tqitrR181dfXl7NNAAA4wqg+1eHAgQMxf/78WLduXUyYMOGE1y1btix6enoGX3v37h3FXQIAkMFZ5UyeMGFCVFZWRnd395Dx7u7umDRp0hHzf/7zn8dbb70Vc+bMGRwbGBj43YXPOitee+21uPjii49YVyqVolQqlbM1AAA4rrLu+FZVVcXMmTOjvb19cGxgYCDa29ujsbHxiPmXXnppvPLKK9HZ2Tn4+uxnPxvXX399dHZ2+goDAABjpqw7vhERLS0tsXDhwpg1a1bMnj07Vq9eHQcPHoxFixZFRMSCBQti6tSp0dbWFtXV1XHZZZcNWX/++edHRBwxDgAAo6ns8J03b17s27cvVqxYEV1dXTFjxozYvHnz4A+87dmzJyoq/IFwAACcXsYVRVGc6k28n97e3qitrY2enp6oqak51dsBAGCUjUb/uTULAEAKwhcAgBSELwAAKQhfAABSEL4AAKQgfAEASEH4AgCQgvAFACAF4QsAQArCFwCAFIQvAAApCF8AAFIQvgAApCB8AQBIQfgCAJCC8AUAIAXhCwBACsIXAIAUhC8AACkIXwAAUhC+AACkIHwBAEhB+AIAkILwBQAgBeELAEAKwhcAgBSELwAAKQhfAABSEL4AAKQgfAEASEH4AgCQgvAFACAF4QsAQArCFwCAFIQvAAApCF8AAFIQvgAApCB8AQBIQfgCAJCC8AUAIAXhCwBACsIXAIAUhC8AACkIXwAAUhC+AACkIHwBAEhB+AIAkILwBQAgBeELAEAKwhcAgBSELwAAKQhfAABSEL4AAKQgfAEASEH4AgCQgvAFACAF4QsAQArCFwCAFIQvAAApCF8AAFIQvgAApCB8AQBIQfgCAJCC8AUAIAXhCwBACsIXAIAUhC8AACkIXwAAUhC+AACkIHwBAEhB+AIAkILwBQAgBeELAEAKwhcAgBSELwAAKQhfAABSEL4AAKQgfAEASEH4AgCQgvAFACAF4QsAQArCFwCAFIQvAAApCF8AAFIQvgAApDCs8F2zZk1MmzYtqquro6GhIbZu3XrMuevWrYtrr702xo8fH+PHj4+mpqbjzgcAgNFQdvhu2LAhWlpaorW1NbZv3x7Tp0+P5ubmePvtt486f8uWLXHTTTfFj370o+jo6Ij6+vr4zGc+E7/85S9PevMAAHCixhVFUZSzoKGhIa666qp49NFHIyJiYGAg6uvr484774ylS5e+7/r+/v4YP358PProo7FgwYITumZvb2/U1tZGT09P1NTUlLNdAADOQKPRf2Xd8e3r64tt27ZFU1PTH96goiKampqio6PjhN7j3Xffjffeey8uuOCCY845dOhQ9Pb2DnkBAMDJKCt89+/fH/39/VFXVzdkvK6uLrq6uk7oPe6+++6YMmXKkHj+Y21tbVFbWzv4qq+vL2ebAABwhDF9qsOqVati/fr18dxzz0V1dfUx5y1btix6enoGX3v37h3DXQIA8EF0VjmTJ0yYEJWVldHd3T1kvLu7OyZNmnTctQ899FCsWrUqfvjDH8YVV1xx3LmlUilKpVI5WwMAgOMq645vVVVVzJw5M9rb2wfHBgYGor29PRobG4+57sEHH4wHHnggNm/eHLNmzRr+bgEAYJjKuuMbEdHS0hILFy6MWbNmxezZs2P16tVx8ODBWLRoUURELFiwIKZOnRptbW0REfHP//zPsWLFinj66adj2rRpg98F/tCHPhQf+tCHRvCjAADAsZUdvvPmzYt9+/bFihUroqurK2bMmBGbN28e/IG3PXv2REXFH24kf/Ob34y+vr74m7/5myHv09raGl/5yldObvcAAHCCyn6O76ngOb4AALmc8uf4AgDAmUr4AgCQgvAFACAF4QsAQArCFwCAFIQvAAApCF8AAFIQvgAApCB8AQBIQfgCAJCC8AUAIAXhCwBACsIXAIAUhC8AACkIXwAAUhC+AACkIHwBAEhB+AIAkILwBQAgBeELAEAKwhcAgBSELwAAKQhfAABSEL4AAKQgfAEASEH4AgCQgvAFACAF4QsAQArCFwCAFIQvAAApCF8AAFIQvgAApCB8AQBIQfgCAJCC8AUAIAXhCwBACsIXAIAUhC8AACkIXwAAUhC+AACkIHwBAEhB+AIAkILwBQAgBeELAEAKwhcAgBSELwAAKQhfAABSEL4AAKQgfAEASEH4AgCQgvAFACAF4QsAQArCFwCAFIQvAAApCF8AAFIQvgAApCB8AQBIQfgCAJCC8AUAIAXhCwBACsIXAIAUhC8AACkIXwAAUhC+AACkIHwBAEhB+AIAkILwBQAgBeELAEAKwhcAgBSELwAAKQhfAABSEL4AAKQgfAEASEH4AgCQgvAFACAF4QsAQArCFwCAFIQvAAApCF8AAFIQvgAApCB8AQBIQfgCAJCC8AUAIAXhCwBACsIXAIAUhhW+a9asiWnTpkV1dXU0NDTE1q1bjzv/e9/7Xlx66aVRXV0dl19+eWzatGlYmwUAgOEqO3w3bNgQLS0t0draGtu3b4/p06dHc3NzvP3220ed//LLL8dNN90Ut9xyS+zYsSPmzp0bc+fOjZ/97GcnvXkAADhR44qiKMpZ0NDQEFdddVU8+uijERExMDAQ9fX1ceedd8bSpUuPmD9v3rw4ePBg/OAHPxgc+8u//MuYMWNGrF279oSu2dvbG7W1tdHT0xM1NTXlbBcAgDPQaPTfWeVM7uvri23btsWyZcsGxyoqKqKpqSk6OjqOuqajoyNaWlqGjDU3N8fzzz9/zOscOnQoDh06NPjrnp6eiPjd3wAAAD74ft99Zd6jPa6ywnf//v3R398fdXV1Q8br6upi165dR13T1dV11PldXV3HvE5bW1vcf//9R4zX19eXs10AAM5w//M//xO1tbUj8l5lhe9YWbZs2ZC7xO+88058+MMfjj179ozYB+fM0dvbG/X19bF3715fdUnI+efm/HNz/rn19PTEhRdeGBdccMGIvWdZ4TthwoSorKyM7u7uIePd3d0xadKko66ZNGlSWfMjIkqlUpRKpSPGa2tr/YOfWE1NjfNPzPnn5vxzc/65VVSM3NN3y3qnqqqqmDlzZrS3tw+ODQwMRHt7ezQ2Nh51TWNj45D5EREvvvjiMecDAMBoKPurDi0tLbFw4cKYNWtWzJ49O1avXh0HDx6MRYsWRUTEggULYurUqdHW1hYREXfddVdcd9118fDDD8eNN94Y69evj5/+9Kfx+OOPj+wnAQCA4yg7fOfNmxf79u2LFStWRFdXV8yYMSM2b948+ANse/bsGXJL+uqrr46nn3467r333rjnnnviL/7iL+L555+Pyy677ISvWSqVorW19ahff+CDz/nn5vxzc/65Of/cRuP8y36OLwAAnIlG7tvCAABwGhO+AACkIHwBAEhB+AIAkMJpE75r1qyJadOmRXV1dTQ0NMTWrVuPO/973/teXHrppVFdXR2XX355bNq0aYx2ymgo5/zXrVsX1157bYwfPz7Gjx8fTU1N7/vPC6e3cn///9769etj3LhxMXfu3NHdIKOq3PN/5513YvHixTF58uQolUpxySWX+HfAGazc81+9enV89KMfjXPOOSfq6+tjyZIl8dvf/naMdstI+fGPfxxz5syJKVOmxLhx4+L5559/3zVbtmyJT37yk1EqleIjH/lIPPXUU+VfuDgNrF+/vqiqqiqefPLJ4r/+67+K2267rTj//POL7u7uo87/yU9+UlRWVhYPPvhg8eqrrxb33ntvcfbZZxevvPLKGO+ckVDu+d98883FmjVrih07dhQ7d+4s/u7v/q6ora0t/vu//3uMd85IKPf8f+/NN98spk6dWlx77bXFX//1X4/NZhlx5Z7/oUOHilmzZhU33HBD8dJLLxVvvvlmsWXLlqKzs3OMd85IKPf8v/Od7xSlUqn4zne+U7z55pvFCy+8UEyePLlYsmTJGO+ck7Vp06Zi+fLlxbPPPltERPHcc88dd/7u3buLc889t2hpaSleffXV4hvf+EZRWVlZbN68uazrnhbhO3v27GLx4sWDv+7v7y+mTJlStLW1HXX+5z73ueLGG28cMtbQ0FD8/d///ajuk9FR7vn/scOHDxfnnXde8e1vf3u0tsgoGs75Hz58uLj66quLb33rW8XChQuF7xms3PP/5je/WVx00UVFX1/fWG2RUVTu+S9evLj49Kc/PWSspaWluOaaa0Z1n4yuEwnfL3/5y8UnPvGJIWPz5s0rmpuby7rWKf+qQ19fX2zbti2ampoGxyoqKqKpqSk6OjqOuqajo2PI/IiI5ubmY87n9DWc8/9j7777brz33ntxwQUXjNY2GSXDPf+vfvWrMXHixLjlllvGYpuMkuGc//e///1obGyMxYsXR11dXVx22WWxcuXK6O/vH6ttM0KGc/5XX311bNu2bfDrELt3745NmzbFDTfcMCZ75tQZqfYr+09uG2n79++P/v7+wT/57ffq6upi165dR13T1dV11PldXV2jtk9Gx3DO/4/dfffdMWXKlCN+Q3D6G875v/TSS/HEE09EZ2fnGOyQ0TSc89+9e3f8x3/8R3z+85+PTZs2xRtvvBFf/OIX47333ovW1tax2DYjZDjnf/PNN8f+/fvjU5/6VBRFEYcPH4477rgj7rnnnrHYMqfQsdqvt7c3fvOb38Q555xzQu9zyu/4wslYtWpVrF+/Pp577rmorq4+1dthlB04cCDmz58f69atiwkTJpzq7XAKDAwMxMSJE+Pxxx+PmTNnxrx582L58uWxdu3aU701xsCWLVti5cqV8dhjj8X27dvj2WefjY0bN8YDDzxwqrfGGeKU3/GdMGFCVFZWRnd395Dx7u7umDRp0lHXTJo0qaz5nL6Gc/6/99BDD8WqVavihz/8YVxxxRWjuU1GSbnn//Of/zzeeuutmDNnzuDYwMBAREScddZZ8dprr8XFF188uptmxAzn9//kyZPj7LPPjsrKysGxj33sY9HV1RV9fX1RVVU1qntm5Azn/O+7776YP39+3HrrrRERcfnll8fBgwfj9ttvj+XLl0dFhft5H1THar+ampoTvtsbcRrc8a2qqoqZM2dGe3v74NjAwEC0t7dHY2PjUdc0NjYOmR8R8eKLLx5zPqev4Zx/RMSDDz4YDzzwQGzevDlmzZo1FltlFJR7/pdeemm88sor0dnZOfj67Gc/G9dff310dnZGfX39WG6fkzSc3//XXHNNvPHGG4P/wRMR8frrr8fkyZNF7xlmOOf/7rvvHhG3v/+PoN/9jBQfVCPWfuX93N3oWL9+fVEqlYqnnnqqePXVV4vbb7+9OP/884uurq6iKIpi/vz5xdKlSwfn/+QnPynOOuus4qGHHip27txZtLa2epzZGazc81+1alVRVVVVPPPMM8WvfvWrwdeBAwdO1UfgJJR7/n/MUx3ObOWe/549e4rzzjuv+Id/+IfitddeK37wgx8UEydOLL72ta+dqo/ASSj3/FtbW4vzzjuv+Ld/+7di9+7dxb//+78XF198cfG5z33uVH0EhunAgQPFjh07ih07dhQRUTzyyCPFjh07il/84hdFURTF0qVLi/nz5w/O//3jzP7pn/6p2LlzZ7FmzZoz93FmRVEU3/jGN4oLL7ywqKqqKmbPnl3853/+5+Bfu+6664qFCxcOmf/d7363uOSSS4qqqqriE5/4RLFx48Yx3jEjqZzz//CHP1xExBGv1tbWsd84I6Lc3///P+F75iv3/F9++eWioaGhKJVKxUUXXVR8/etfLw4fPjzGu2aklHP+7733XvGVr3yluPjii4vq6uqivr6++OIXv1j87//+79hvnJPyox/96Kj/Lv/9eS9cuLC47rrrjlgzY8aMoqqqqrjooouKf/3Xfy37uuOKwv8bAADgg++Uf8cXAADGgvAFACAF4QsAQArCFwCAFIQvAAApCF8AAFIQvgAApCB8AQBIQfgCAJCC8AUAIAXhCwBACsIXAIAU/h84Ea1h0Fa+MwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "plt.plot(range(len(loss_list_train)), loss_list_train, color= 'red')\n",
    "# plt.plot(range(len(loss_list_val)), loss_list_val, color = 'blue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6922897782236395\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for input, target in test_loader:\n",
    "        input, target = input.to('cuda'), target.to('cuda')\n",
    "        output = torch.round(model(input))\n",
    "        all_preds.extend(output.to('cpu'))\n",
    "        all_labels.extend(target.to('cpu'))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(all_preds, all_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
