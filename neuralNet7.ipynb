{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, p1, p2):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Linear(31, 50, bias= True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 50, bias= True),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p= p1),\n",
    "            nn.Linear(50, 45, bias = True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(45, 40, bias= True),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(40, 40, bias= True),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Dropout(p= p2),\n",
    "            nn.Linear(40, 30, bias= True),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(30, 25, bias= True),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(25, 20, bias= True),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(20, 15, bias= True),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(15, 10, bias = True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 5, bias = True),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.classify = nn.Sequential(\n",
    "            nn.Linear(5, 1, bias= True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.classify(self.features(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__()\n",
    "        self.x = torch.tensor(x.values, dtype= torch.float32)\n",
    "        self.y = torch.tensor(y.values, dtype= torch.float32)\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.x[index], self.y[index]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, ytrain, xtest, ytest = pd.read_csv('./X_train.csv', header= None, index_col = None), pd.read_csv('./y_train.csv', header = None, index_col = None), pd.read_csv('./X_test.csv', header = None, index_col = None), pd.read_csv('./y_test.csv', header = None, index_col = None)\n",
    "train_data = Data(x= xtrain, y= ytrain)\n",
    "test_data = Data(x= xtest, y= ytest)\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle= True)\n",
    "test_loader = DataLoader(test_data, batch_size= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (features): Sequential(\n",
       "    (0): Linear(in_features=31, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Dropout(p=0.3, inplace=False)\n",
       "    (5): Linear(in_features=50, out_features=45, bias=True)\n",
       "    (6): ReLU()\n",
       "    (7): Linear(in_features=45, out_features=40, bias=True)\n",
       "    (8): Sigmoid()\n",
       "    (9): Linear(in_features=40, out_features=40, bias=True)\n",
       "    (10): Sigmoid()\n",
       "    (11): Dropout(p=0.6, inplace=False)\n",
       "    (12): Linear(in_features=40, out_features=30, bias=True)\n",
       "    (13): Sigmoid()\n",
       "    (14): Linear(in_features=30, out_features=25, bias=True)\n",
       "    (15): Sigmoid()\n",
       "    (16): Linear(in_features=25, out_features=20, bias=True)\n",
       "    (17): Sigmoid()\n",
       "    (18): Linear(in_features=20, out_features=15, bias=True)\n",
       "    (19): Sigmoid()\n",
       "    (20): Linear(in_features=15, out_features=10, bias=True)\n",
       "    (21): ReLU()\n",
       "    (22): Linear(in_features=10, out_features=5, bias=True)\n",
       "    (23): ReLU()\n",
       "  )\n",
       "  (classify): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=1, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network(0.3, 0.6)\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001, weight_decay= 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss - 3355.248402059078\n",
      "loss - 3338.4548465013504\n",
      "loss - 3338.4741723537445\n",
      "loss - 3338.4853679537773\n",
      "loss - 3338.4663470983505\n",
      "loss - 3338.475383102894\n",
      "loss - 3338.4505479335785\n",
      "loss - 3338.487676501274\n",
      "loss - 3338.4568335413933\n",
      "loss - 3338.4292715787888\n",
      "loss - 3338.4705654382706\n",
      "loss - 3338.477103292942\n",
      "loss - 3338.4595419168472\n",
      "loss - 3338.457520067692\n",
      "loss - 3338.4772418141365\n",
      "loss - 3338.4736258387566\n",
      "loss - 3338.45359647274\n",
      "loss - 3338.4330908060074\n",
      "loss - 3338.4662379026413\n",
      "loss - 3338.469562768936\n",
      "loss - 3338.4436337947845\n",
      "loss - 3338.4419174194336\n",
      "loss - 3338.4545649290085\n",
      "loss - 3338.4704152941704\n",
      "loss - 3338.441410958767\n",
      "loss - 3338.4762080311775\n",
      "loss - 3338.474545478821\n",
      "loss - 3338.4597098231316\n",
      "loss - 3338.459169447422\n",
      "loss - 3338.4485228657722\n",
      "loss - 3338.468313395977\n",
      "loss - 3338.43308699131\n",
      "loss - 3338.449570477009\n",
      "loss - 3338.435056209564\n",
      "loss - 3338.465665638447\n",
      "loss - 3338.4342972636223\n",
      "loss - 3338.42248994112\n",
      "loss - 3338.4530072808266\n",
      "loss - 3338.4800904393196\n",
      "loss - 3338.4547920823097\n",
      "loss - 3338.4779589772224\n",
      "loss - 3338.4603860378265\n",
      "loss - 3338.478222489357\n",
      "loss - 3338.4741483926773\n",
      "loss - 3338.489750444889\n",
      "loss - 3338.454084098339\n",
      "loss - 3338.472663164139\n",
      "loss - 3338.43944889307\n",
      "loss - 3338.465188384056\n",
      "loss - 3338.4833886027336\n",
      "loss - 3338.4340970516205\n",
      "loss - 3338.4334368109703\n",
      "loss - 3338.4182476997375\n",
      "loss - 3338.4562531113625\n",
      "loss - 3338.455598652363\n",
      "loss - 3338.4399612545967\n",
      "loss - 3338.4362865686417\n",
      "loss - 3338.456078529358\n",
      "loss - 3338.4732939600945\n",
      "loss - 3338.45307636261\n",
      "loss - 3338.4582941532135\n",
      "loss - 3338.429070651531\n",
      "loss - 3338.444922029972\n",
      "loss - 3338.4436665177345\n",
      "loss - 3338.46162211895\n",
      "loss - 3338.450594186783\n",
      "loss - 3338.465219974518\n",
      "loss - 3338.420894443989\n",
      "loss - 3338.4612263441086\n",
      "loss - 3338.464981853962\n",
      "loss - 3338.451437830925\n",
      "loss - 3338.4568886756897\n",
      "loss - 3338.4629538059235\n",
      "loss - 3338.4255539774895\n",
      "loss - 3338.4602944254875\n",
      "loss - 3338.421409010887\n",
      "loss - 3338.449380517006\n",
      "loss - 3338.463939368725\n",
      "loss - 3338.479046702385\n",
      "loss - 3338.4611261487007\n",
      "loss - 3338.4127265810966\n",
      "loss - 3338.468350350857\n",
      "loss - 3338.438035607338\n",
      "loss - 3338.4708544015884\n",
      "loss - 3338.4578322172165\n",
      "loss - 3338.48877710104\n",
      "loss - 3338.4369332790375\n",
      "loss - 3338.459610581398\n",
      "loss - 3338.476287841797\n",
      "loss - 3338.473561704159\n",
      "loss - 3338.472500741482\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m output = model(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m      8\u001b[39m loss = criterion(output, target)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m optimizer.step()\n\u001b[32m     11\u001b[39m running_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Suchit\\Desktop\\Deep-Learning\\venv\\Lib\\site-packages\\torch\\_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Suchit\\Desktop\\Deep-Learning\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Suchit\\Desktop\\Deep-Learning\\venv\\Lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(500):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for input, target in train_loader:\n",
    "        input, target = input.to('cuda'), target.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'loss - {running_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6132886675504281\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for input, target in test_loader:\n",
    "        input, target = input.to('cuda'), target.to('cuda')\n",
    "        output = torch.round(model(input))\n",
    "        all_preds.extend(output.to('cpu'))\n",
    "        all_labels.extend(target.to('cpu'))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(all_preds, all_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
